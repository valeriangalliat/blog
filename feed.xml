<?xml version="1.0" encoding="utf-8" ?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>CodeJam</title>
  <subtitle>Hey, I‚Äôm Val, welcome to my blog!</subtitle>
  <link href="https://www.codejam.info/feed.xml" rel="self" />
  <link href="https://www.codejam.info/" />
  <id>https://www.codejam.info/</id>
  <updated>2023-04-05T22:07:59.989Z</updated>
  <author>
    <name>Val</name>
  </author>
  <entry>
    <title>Archiving Google Photos offline to free up space</title>
    <link href="https://www.codejam.info/2023/04/archiving-google-photos.html" />
    <id>https://www.codejam.info/2023/04/archiving-google-photos.html</id>
    <updated>2023-04-02T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>If you backup your phone photos to Google Photos automatically, and you
don‚Äôt pay for some kind of Google One subscription, you‚Äôll run sooner or
later into the 15 GB storage limit of your Google account.</p>
<p>15 GB is not a lot, especially when you consider than my Pixel 6a takes
pictures that are easily 3 to 5 MB each. üò¨</p>
<p>To be fair, if you want convenience and you value your time, Google
One‚Äôs $20/year for 100 GB is a pretty damn good deal. Same goes for the
higher options with more storage if you need.</p>
<p>But if you don‚Äôt like recurring bills like me, and you find it overkill
to keep that many old photos in the cloud, read on.</p>
<h2 id="my-protocol-for-archiving-photos-away-from-google" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#my-protocol-for-archiving-photos-away-from-google"><span>My protocol for archiving photos away from Google</span></a></h2>
<p>In order to save space, I‚Äôll periodically archive my old photos outside
of Google Photos.</p>
<p>This protocol is designed to archive photos <em>from the phone</em> that are
<em>backed up</em> to Google Photos, but preserving the phone‚Äôs original
arborescence. Google Photos doesn‚Äôt have the path information, only the
filename, so backing up <em>from Google Photos</em> directly would not work for
this use case.</p>
<p>The downside is that this doesn‚Äôt cover the case where you have photos
in Google Photos that are <em>not</em> on your phone.</p>
<p>Also it‚Äôs designed for a single phone backing up to a Google Photos
account that‚Äôs used <em>solely</em> for that device. Multiple devices sharing
the same Google Photos is not supported.</p>
<p>With that said, here‚Äôs how I do it.</p>
<h3 id="1-sync-phone-to-computer" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#1-sync-phone-to-computer"><span>1. Sync phone to computer</span></a></h3>
<p>First, I use <a href="https://syncthing.net/">Syncthing</a> to sync the contents of
my phone to a hard drive connected to my computer.</p>
<p>I configure Syncthing as ‚Äúsend only‚Äù on my phone, and ‚Äúreceive only‚Äù on
my computer, and I configure it to sync the root directory of my phone
(which can be tricky, <a href="https://www.codejam.info/2023/04/syncthing-root-directory.html">but possible</a>).</p>
<p><strong>After the sync is complete, I turn off Syncthing from my computer, to
make sure no incremental updates will happen during the archive
process.</strong></p>
<h3 id="2-copy-synced-folder-to-archive" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#2-copy-synced-folder-to-archive"><span>2. Copy synced folder to archive</span></a></h3>
<p>For this example, let‚Äôs assume I synced my phone to a
<code>/Volumes/Syncthing/Phone</code> directory, and I want to archive my old
photos in <code>/Volumes/Archive/Phone</code>.</p>
<p>I‚Äôll run the following command to copy the phone contents to my archive
directory:</p>
<pre><code class="hljs language-sh"><span class="hljs-built_in">cp</span> -a /Volumes/Syncthing/Phone/ /Volumes/Archive/Phone/
</code></pre>
<div class="note">
<p><strong>Note:</strong> the reason I copy the whole phone contents is because I want
to catch <em>all</em> photos and videos that are backed up to Google Photos.
Typically, apps like Messenger, Whats App, Signal, etc. all store photos
in different directories, so syncing only <code>DCIM/Camera</code> would not be
enough.</p>
</div>
<p>If the target directory already exists, this will append new files to it
(and overwrite them if a file already exists there)!</p>
<p>Also if the directory already exists, the trailing slashes are
important.</p>
<div class="note">
<p><strong>Note:</strong> if both directories are on the same filesystem, and you‚Äôre not
appending to an existing archive, you may use <code>mv</code> instead, but then
make sure to recreate the Syncthing directory and put back its
<code>.stfolder</code> (required for Syncthing to recognize it) and <code>.stignore</code> if
you have one!</p>
</div>
<h3 id="3-delete-everything-from-google-photos" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#3-delete-everything-from-google-photos"><span>3. Delete everything from Google Photos</span></a></h3>
<p>Not necessarily everything, but well, everything you want to delete to
free up space.</p>
<p>You can do it from your phone, or from Google Photos on your computer,
or on the web.</p>
<div class="note">
<p><strong>Note:</strong> be careful! If you have photos that are <em>only</em> on Google
Photos but not stored on your phone storage, the previous step didn‚Äôt
archive them. You need to make sure to download them from Google Photos
in the first place. Doing that in an automated way is not covered in
this post.</p>
</div>
<p>As an abundance of caution, you may want to double check that the number
of photos/videos you have on Google Photos matches exactly with the
number of photos/videos you have on your phone before doing that.</p>
<p>If there‚Äôs any mismatch, try to find where the difference it to make
sure you‚Äôre not accidentally losing any photo.</p>
<p>Alternatively, you can <a href="https://www.codejam.info/2023/04/archiving-google-photos.html#bonus-script-to-list-all-your-google-photos-using-the-api">use the Google Photos API</a>
to list all the filenames on Google Photos, and ensure you have a match
in your archive prior to deleting. Otherwise, you‚Äôll know the names of
the missing ones that you have to download.</p>
<div class="note">
<p><strong>Note:</strong> if you deleted the photos from the web or desktop app, make
sure to wait that the deletion is propagated to your phone before you
continue!</p>
</div>
<h3 id="4-sync-phone-to-computer-again" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#4-sync-phone-to-computer-again"><span>4. Sync phone to computer again</span></a></h3>
<p>Again with Syncthing in my case, I do a sync following the deletion.</p>
<div class="note">
<p><strong>Note:</strong> you may want to exclude <code>.trashed-*</code> files in your
<code>.stignore</code>, otherwise the photos you deleted will still be synced while
they‚Äôre in the trash.</p>
</div>
<p>Now in our example, <code>/Volumes/Syncthing/Phone</code> contains just the
photos we decided to keep around in Google Photos, while
<code>/Volumes/Archive/Phone</code> contains <em>all</em> the photos (also including the
ones we kept around).</p>
<p>On top of that, both directories contains <em>all other files</em> from the
phone, that are not managed by Google Photos.</p>
<div class="note">
<p><strong>Note:</strong> this process is not very efficient if you have a lot of files
that are not photos and videos, e.g. music and downloads. You may want
to ignore those directories in the earlier steps to avoid copying them
around unnecessarily!</p>
</div>
<h3 id="5-remove-the-overlap" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#5-remove-the-overlap"><span>5. Remove the overlap</span></a></h3>
<p>To avoid that duplication, we can remove all files from the archive that
are still in the Syncthing directory. That is, all the photos/videos we
kept, as well as all the files in the phone storage that are not managed
by Google Photos.</p>
<pre><code class="hljs language-sh">(<span class="hljs-built_in">cd</span> /Volumes/Syncthing/Phone &amp;&amp; find . -<span class="hljs-built_in">type</span> f) | <span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> f; <span class="hljs-keyword">do</span> <span class="hljs-built_in">rm</span> -v <span class="hljs-string">&quot;/Volumes/Archive/Phone/<span class="hljs-variable">$f</span>&quot;</span>; <span class="hljs-keyword">done</span>
</code></pre>
<p>Now, the archive directory only contains what we removed from Google
Photos (and from the phone), but there‚Äôs no duplicates!</p>
<h3 id="6-profit" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#6-profit"><span>6. Profit!</span></a></h3>
<p>You can now enjoy all the space you freed up by archiving your photos
and videos away from Google Photos!</p>
<p>Repeat every time you‚Äôre close to running out of storage. üòâ</p>
<h2 id="about-the-google-photos-app-home-page" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#about-the-google-photos-app-home-page"><span>About the Google Photos app ‚Äúhome page‚Äù</span></a></h2>
<p>I think there may be some display bugs when deleting <em>a lot</em> of photos
from Google Photos at once. For some reason the main photos list of my
Google Photos still shows a few of the photos I deleted! They‚Äôre in a
weird state where the UI offers me download them to my device (as if
they‚Äôre not on the device already), but also shows me a local path to
the file as if it was on device (but the photo is not actually there).</p>
<p>I‚Äôm thinking this issue will be gone when the photos in the trash are
permanently deleted, so this doesn‚Äôt concern me too much. What‚Äôs visible
in Google Photos on the web (and in their API) is consistent with the
state I want, and what‚Äôs on my phone‚Äôs raw storage is consistent too.</p>
<h2 id="what-about-motion-photos" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#what-about-motion-photos"><span>What about motion photos?</span></a></h2>
<p>Google‚Äôs motion photos are the equivalent of Apple‚Äôs live photos: a
photo that also contains a short video of the ‚Äúmoment‚Äù it was captured.</p>
<p>What happens to those during our archival process? Well, it‚Äôs
complicated.</p>
<p>In short, don‚Äôt worry, they‚Äôre backed up and the little video that goes
with the motion photo is not going to be lost, but you won‚Äôt be able to
watch the ‚Äúlive‚Äù part anymore, you‚Äôll only see the still picture.</p>
<p>The reason is that Google stores the MP4 video part at the end of the JPEG
file. This doesn‚Äôt prevent displaying the image, but there‚Äôs currently
no photo viewer other than Google Photos that knows to extract that MP4
section following the JPEG data, and display it properly.</p>
<p>So if you want to see the live part of a motion photo, you‚Äôll have to
re-import it to Google Photos.</p>
<p>Alternatively, you can extract the MP4 part of the motion photo to a
different file, which you can do by using a script like
<a href="https://mjanja.ch/2021/10/stripping-embedded-mp4s-out-of-android-12-motion-photos/">detailed in this post</a>.</p>
<div class="note">
<p><strong>Note:</strong> if you use the script from the above post on macOS, you‚Äôll
need GNU <code>grep</code> in order find the byte offset of the MP4 header.</p>
<p>This means you‚Äôll have to <code>brew install coreutils</code> and replace <code>grep</code> by
<code>ggrep</code> in the script for it to work.</p>
</div>
<h2 id="bonus-script-to-list-all-your-google-photos-using-the-api" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#bonus-script-to-list-all-your-google-photos-using-the-api"><span>Bonus: script to list all your Google Photos using the API</span></a></h2>
<p>In the previous section, we saw it can be useful to list all the photos
from Google Photos (not necessarily on any of your devices) prior to
running the archiving process, to make sure you can catch the ones that
are not backed up anywhere.</p>
<p>You can put this script in <code>photos.mjs</code> and run as <code>node photos.mjs</code>.
You‚Äôll need to put a Google OAuth access token with access to your
Google Photos for this to work.</p>
<p>If you want to generate one from the CLI, check out my
<a href="https://www.codejam.info/2021/02/google-oauth-from-cli-application.html#update-local-server-redirect">article on the subject</a>.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> fs <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;node:fs/promises&#x27;</span>

<span class="hljs-keyword">const</span> accessToken = <span class="hljs-string">&#x27;YOUR_ACCESS_TOKEN&#x27;</span>

<span class="hljs-keyword">let</span> pageToken = <span class="hljs-string">&#x27;&#x27;</span>
<span class="hljs-keyword">let</span> pages = []

<span class="hljs-keyword">do</span> {
  <span class="hljs-keyword">const</span> url = <span class="hljs-string">&#x27;https://photoslibrary.googleapis.com/v1/mediaItems?pageSize=100&amp;pageToken=&#x27;</span> + <span class="hljs-built_in">encodeURIComponent</span>(pageToken)

  <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(url)

  <span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> <span class="hljs-title function_">fetch</span>(url, {
    <span class="hljs-attr">headers</span>: {
      <span class="hljs-string">&#x27;Authorization&#x27;</span>: <span class="hljs-string">`Bearer <span class="hljs-subst">${accessToken}</span>`</span>
    }
  })

  <span class="hljs-keyword">const</span> json = <span class="hljs-keyword">await</span> response.<span class="hljs-title function_">json</span>()

  pages.<span class="hljs-title function_">push</span>(json)

  pageToken = json.<span class="hljs-property">nextPageToken</span>
} <span class="hljs-keyword">while</span> (pageToken)

<span class="hljs-keyword">await</span> fs.<span class="hljs-title function_">writeFile</span>(<span class="hljs-string">&#x27;pages.json&#x27;</span>, <span class="hljs-title class_">JSON</span>.<span class="hljs-title function_">stringify</span>(pages, <span class="hljs-literal">null</span>, <span class="hljs-number">2</span>))
</code></pre>
<p>This will fetch all pages from the Google Photos API and dump them in a
<code>pages.json</code> file. You can then iterate through it to do whatever
operations you need to, e.g. making sure you don‚Äôt leave any photo
around before deleting them from Google.</p>
<h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/archiving-google-photos.html#conclusion"><span>Conclusion</span></a></h2>
<p>Archiving photos away from Google Photos is not trivial, but possible.</p>
<p>If you care about not losing any of your photos, I recommend double
checking at every step that you‚Äôre not accidentally forgetting any file.</p>
<p>When done well, this allows to periodically free up some space from your
Google account without actually having to get rid of your photos and
videos! They‚Äôll still be available on your archive hard drive if you
want to. Your old photos are not as handy as if they were in the cloud,
but you know you can access them if needed.</p>
<p>Overall, you‚Äôre probably better off just paying Google to increase your
storage, but if you‚Äôre really motivated, I hope you can find inspiration
in the process I described in this post.</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Start a conversation on <a href="https://twitter.com/valeriangalliat">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Syncthing: sync phone root directory (all internal storage)</title>
    <link href="https://www.codejam.info/2023/04/syncthing-root-directory.html" />
    <id>https://www.codejam.info/2023/04/syncthing-root-directory.html</id>
    <updated>2023-04-02T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>If you use Syncthing on your phone, it may not let you select the
phone‚Äôs root directory as a shared folder source! At least that‚Äôs the
case on my phone running Android 13.</p>
<figure class="center">
  <img alt="Syncthing web GUI showing root directory path as text" srcset="../../img/2023/04/syncthing-forbidden.png 3x">
</figure>
<p>As you can see, ‚Äúuse this folder‚Äù is greyed out and there‚Äôs a warning
the folder can‚Äôt be used for privacy reasons.</p>
<p>But I own that phone and I don‚Äôt like being told what to do. In our
case, I want to be able to sync <strong>all</strong> of my phone‚Äôs storage to my
computer, as a backup system.</p>
<p>So how to circumvent that?</p>
<p>Turns out we can do that through Syncthing‚Äôs lesser known ‚Äúweb GUI‚Äù!</p>
<p>You can find it in the left menu (where you also exit Syncthing from).
It will open the web version of Syncthing. From there, instead of
selecting the directory to sync from your phone‚Äôs native folder picker
(which may prevent you to use the root directory), you can just <em>input a
path</em> as plain text.</p>
<figure class="center">
  <img alt="Syncthing web GUI showing root directory path as text" srcset="../../img/2023/04/syncthing-web-gui.png 3x">
</figure>
<p>Enter <code>/storage/emuilated/0</code> (or simply <code>~</code>), and there you go, you have
a Syncthing folder that syncs all of your phone‚Äôs internal storage! üôè</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Start a conversation on <a href="https://twitter.com/valeriangalliat">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Getting rid of ghost login items in macOS Ventura</title>
    <link href="https://www.codejam.info/2023/04/ghost-login-items-macos-ventura.html" />
    <id>https://www.codejam.info/2023/04/ghost-login-items-macos-ventura.html</id>
    <updated>2023-04-02T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Let‚Äôs say you uninstalled an app on macOS Ventura, and you see some
leftovers from that app in <strong>system settings</strong>, <strong>general</strong>, <strong>login
items</strong>:</p>
<figure class="center">
  <img alt="macOS login items with leftover app that shouldn‚Äôt be there" srcset="../../img/2023/04/login-items-dirty.png 2x">
</figure>
<p>Here‚Äôs a few tips to solve it.</p>
<h2 id="reboot" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/ghost-login-items-macos-ventura.html#reboot"><span>Reboot</span></a></h2>
<p>More often than not, it seems that after removing login items and/or the
app behind then, it takes a reboot of macOS Ventura until they‚Äôre
‚Äúgarbage collected‚Äù from system settings. That‚Äôs the first thing you
should try.</p>
<h2 id="check-your-trash" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/ghost-login-items-macos-ventura.html#check-your-trash"><span>Check your trash!</span></a></h2>
<p>If you moved the app to the trash but didn‚Äôt empty the trash, its login
items are still referenced from the trash! They won‚Äôt go away until you
permanently delete the app (and reboot).</p>
<h2 id="check-leftover-launch-agents-and-daemons" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/ghost-login-items-macos-ventura.html#check-leftover-launch-agents-and-daemons"><span>Check leftover launch agents and daemons</span></a></h2>
<p>There‚Äôs a few places macOS looks for ‚Äúlogin items‚Äù on your filesystem:</p>
<ul>
<li><code>/Library/LaunchAgents</code></li>
<li><code>/Library/LaunchDaemons</code></li>
<li><code>~/Library/LaunchAgents</code></li>
<li><code>~/Library/LaunchDaemons</code></li>
</ul>
<p>Also, same thing under <code>/System/Library</code> but that‚Äôs for macOS own login
items and you have no control over them.</p>
<p>Check the 4 directories above for leftover <code>plist</code> files from the
applications you removed. You may need to do some cleanup. After that,
don‚Äôt forget to reboot!</p>
<h2 id="inspect-backgrounditems-v4-btm" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/ghost-login-items-macos-ventura.html#inspect-backgrounditems-v4-btm"><span>Inspect <code>BackgroundItems-v4.btm</code></span></a></h2>
<p>As shown in <a href="https://www.reddit.com/r/MacOSBeta/comments/w2we6q/cleaning_up_venturas_login_items/">this Reddit post</a>,
the list of login items in Ventura is managed in <code>/private/var/db/com.apple.backgroundtaskmanagement</code>. In my case, in a <code>BackgroundItems-v8.btm</code> file.</p>
<pre><code class="hljs language-console"><span class="hljs-meta prompt_">$ </span><span class="language-bash">file /private/var/db/com.apple.backgroundtaskmanagement/BackgroundItems-v8.btm</span>
Apple binary property list
</code></pre>
<p>As <code>file(1)</code> tells us, this is a binary property list file. We can
inspect it with <code>plutil</code>:</p>
<pre><code class="hljs language-sh">plutil -p /private/var/db/com.apple.backgroundtaskmanagement/BackgroundItems-v8.btm
</code></pre>
<p>This will print the whole structure behind that file. From inspecting
its output, you should be able to determine what‚Äôs behind the ‚Äúghost items‚Äù
that you identified in the system settings. More often than not, it‚Äôll
point to some file or app that you forgot to get rid of, and cleaning
that up will fix your problem (again, after a reboot).</p>
<div class="note">
<p><strong>Note:</strong> if when accessing <code>/private/var/db</code> you get a permission
denied error, even as <code>root</code>, make sure to grant ‚Äúfull disk access‚Äù
permission to your terminal app!</p>
</div>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Start a conversation on <a href="https://twitter.com/valeriangalliat">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Embedding high DPI screenshots at normal size in HTML</title>
    <link href="https://www.codejam.info/2023/04/high-dpi-screenshot-size-html.html" />
    <id>https://www.codejam.info/2023/04/high-dpi-screenshot-size-html.html</id>
    <updated>2023-04-02T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Since I moved to a Retina display, the screenshots I take are twice as
big as before!</p>
<p>This is a problem because, when embedded in an HTML page, they look
ginormous.</p>
<p>Let‚Äôs take a dummy example of some UI element screenshot:</p>
<pre><code class="hljs language-html"><span class="hljs-tag">&lt;<span class="hljs-name">img</span> <span class="hljs-attr">alt</span>=<span class="hljs-string">&quot;Save as popup&quot;</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;save-as-example.png&quot;</span>&gt;</span>
</code></pre>
<figure class="center">
  <img alt="Save as popup" src="https://www.codejam.info/img/2023/04/save-as-example.png">
</figure>
<p>This is huge. Crazy huge. It disturbs the reading flow and you only see
that oversized, slightly blurry image. Just bad.</p>
<p>How to fix it then?</p>
<h2 id="downsize-the-image" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/high-dpi-screenshot-size-html.html#downsize-the-image"><span>Downsize the image</span></a></h2>
<p>We can resize the image by 50% before embedding it. For example using
ImageMagick:</p>
<pre><code class="hljs language-sh">convert save-as-example.png -resize 50% save-as-example-small.png
</code></pre>
<p>This will work, but we introduce a loss in quality from the downscaling
operation. It‚Äôs not gonna be as ‚Äúsharp‚Äù as if the UI element was
rendered at the lower resolution in the first place, without being
downsized at the pixel level later on.</p>
<p>On top of that, when viewed on a high DPI screen, the image will not be
as crisp as what you saw when you took the screenshot, because half the
pixels got lost.</p>
<h2 id="take-the-screenshot-on-a-low-dpi-screen" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/high-dpi-screenshot-size-html.html#take-the-screenshot-on-a-low-dpi-screen"><span>Take the screenshot on a low DPI screen</span></a></h2>
<p>On macOS, if you have an external screen that has a low DPI, you can
take the screenshot on that screen. Then the screenshot will be taken at
a normal-looking native resolution, because there‚Äôs no scaling factor.</p>
<p>The downside is that you need a low DPI screen handy, and to plug it.
Not always applicable.</p>
<p>And on top of that, like the previous method, it won‚Äôt look as good when
viewed on a high DPI screen.</p>
<h2 id="use-srcset-with-a-2x-factor" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/04/high-dpi-screenshot-size-html.html#use-srcset-with-a-2x-factor"><span>Use <code>srcset</code> with a <code>2x</code> factor!</span></a></h2>
<p>If you want to go the lazy and easy way, <code>srcset</code> is the way.</p>
<p>It allows to specify a <em>pixel density descriptor</em> for the image being
referenced. In our case, because the screenshot was rendered at double
the size for the Retina display, we can specify <code>2x</code>.</p>
<pre><code class="hljs language-html"><span class="hljs-tag">&lt;<span class="hljs-name">img</span> <span class="hljs-attr">alt</span>=<span class="hljs-string">&quot;Save as popup&quot;</span> <span class="hljs-attr">srcset</span>=<span class="hljs-string">&quot;save-as-example.png 2x&quot;</span>&gt;</span>
</code></pre>
<figure class="center">
  <img alt="Save as popup" srcset="../../img/2023/04/save-as-example.png 2x">
</figure>
<p>This looks perfect! On a high DPI screen, we get the exact original
quality of the screenshot, as crisp as can be. On a low DPI screen, the
browser knows how to adapt the size of the screenshot to make it look
just right.</p>
<p>The only downside is that for low DPI screens, we‚Äôll still send the
heavier image with twice as much pixels, even if we don‚Äôt need it. If
that‚Äôs a problem for you, then you can use one of the earlier solutions
to generate a <code>1x</code> version of the screenshot, and use it as part of the
<code>srcset</code>.</p>
<div class="note">
<p><strong>Note:</strong> I also use this technique from phone screenshots! Phones
typically have high DPI screens too, and they generate pretty large
screenshots. <code>2x</code> might not be enough to make it look reasonable on a
web page, so feel free to go <code>3x</code> or <code>4x</code> if you want to reduce the size
of the image without altering the original and compromising its quality!</p>
</div>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Join the discussion on <a href="https://twitter.com/valeriangalliat/status/1642615952305954818">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Google Cloud Functions with a static IP: a guide to high throughput NAT</title>
    <link href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html" />
    <id>https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html</id>
    <updated>2023-03-16T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>One day or another, you‚Äôre gonna encounter a firewall with an IP
whitelist. It only accepts connections from specific IP addresses that
were explicitly allowed.</p>
<p>If you have a cloud, serverless and/or autoscaling infrastructure, new
resources are provisioned and deprovisioned automatically to accommodate
your load, and public IPs are dynamically allocated when needed. <strong>You
can‚Äôt predict what public IP address are your requests going to be sent
from</strong>.</p>
<p>This is a problem I‚Äôve needed to solve in virtually every company I‚Äôve
worked with in my career.</p>
<p>The solutions may vary depending on the technologies you use, and your
load patterns. For example, a simple proxy server (TCP, HTTP or SOCKS,
maybe load balanced between a few instances) might go a long way before
you need to resort to more complex solutions.</p>
<p>In this blog post I‚Äôll focus on Google Cloud, and in particular Cloud
Functions, but you might find it useful if you have the same use case
with Cloud Run or Kubernetes, or just need to fine tune a Cloud NAT in
general.</p>
<div class="note">
<p><strong>Note:</strong> this also applies to Firebase Functions, since they‚Äôre
implemented as Cloud Functions.</p>
</div>
<h2 id="building-blocks" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#building-blocks"><span>Building blocks</span></a></h2>
<p>If the proxy server approach doesn‚Äôt meet your requirements, or you just
want a more ‚Äúcloud native‚Äù solution, you‚Äôll need two pieces of
infrastructure in order to route your Cloud Functions or Cloud Run
containers traffic through static IPs: a <strong>VPC connector</strong>,
and a <strong>Cloud NAT</strong>.</p>
<p>If you run on Kubernetes, you only need the Cloud NAT.</p>
<h2 id="vpc-connector" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#vpc-connector"><span>VPC connector</span></a></h2>
<p>The VPC connector, also known as <a href="https://cloud.google.com/vpc/docs/configure-serverless-vpc-access">Serverless VPC Access connector</a>,
is a piece of Google Cloud infrastructure that lets you route the
traffic of Cloud Functions and Cloud Run containers to your <abbr title="Virtual Private Cloud">VPC</abbr>.</p>
<p>This is useful if you want them to access private resources, or in our
case, if you want them to access the internet through static IPs.</p>
<p>The VPC connector is backed by 2 to 10 plain old Compute Engine VMs,
that you can chose from a limited subset of instance sizes (<code>f1-micro</code>,
<code>e2-micro</code> and <code>e2-standard-4</code>). Not far from the naive proxy approach,
but it has to its advantage that those VMs are managed by Google, and
that they have a first-class integration with Cloud Functions and Cloud
Run.</p>
<p>Those instances live in a <code>/28</code> subnet that you allocate for them on
your VPC. <code>/28</code> gives you <a href="https://cloud.google.com/vpc/docs/serverless-vpc-access#ip_address_ranges">14 usable addresses</a>
which is sufficient for the 10 instances upper limit.</p>
<p>A few more things to note:</p>
<ul>
<li>You configure a minimum and maximum number of instances, between 2 and 10.</li>
<li>The connector starts with the minimum number of instances, and will
add more up to the maximum number if your traffic requires it.</li>
<li>After scaling up, the connector doesn‚Äôt scale down and you‚Äôll have to
recreate it if you want to lower the instances count. üôà</li>
</ul>
<p>Useful links:</p>
<ul>
<li><a href="https://cloud.google.com/vpc/docs/serverless-vpc-access">Serverless VPC Access</a></li>
<li><a href="https://cloud.google.com/vpc/docs/configure-serverless-vpc-access">Configure Serverless VPC Access</a></li>
</ul>
<h2 id="cloud-nat" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#cloud-nat"><span>Cloud NAT</span></a></h2>
<p>Cloud NAT is the second piece of the puzzle. It allows you to perform
network address translation (NAT) on Compute Engine VMs that don‚Äôt have
an external IP address.</p>
<p>Even though Cloud NAT depends on a Cloud Router, <a href="https://serverfault.com/q/1078625">it only uses it</a>
for configuring <a href="https://cloudplatform.googleblog.com/2014/04/enter-andromeda-zone-google-cloud-platforms-latest-networking-stack.html">Google Cloud‚Äôs networking stack</a>
but it‚Äôs not involved at the data level: it doesn‚Äôt add an extra hop and
potential bottleneck in your network topology!</p>
<p>In other words, you can expect an identical network bandwidth and
performance with Cloud NAT as if your VMs directly had public IPs, as
long as it‚Äôs appropriately configured for your situation (more on that
later).</p>
<p>Cloud NAT can be configured to dynamically allocate IP addresses as
needed, or use a static pool of IP addresses, which is going to be
useful for us.</p>
<p>In our case, Cloud NAT works hand in hand with the VPC connector VMs,
not only to provide them with internet access, but to do so using static
IPs if we configure the NAT that way!</p>
<p>Useful links:</p>
<ul>
<li><a href="https://cloud.google.com/nat/docs/overview">Cloud NAT overview</a></li>
<li><a href="https://medium.com/bluekiri/high-availability-nat-gateway-at-google-cloud-platform-with-cloud-nat-8a792b1c4cc4">High availability NAT gateway at Google Cloud Platform with Cloud NAT</a></li>
</ul>
<h2 id="configuring-them-together" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#configuring-them-together"><span>Configuring them together</span></a></h2>
<p>I‚Äôll skim over this part as there‚Äôs already decent coverage online:</p>
<ul>
<li><a href="https://dev.to/alvardev/gcp-cloud-functions-with-a-static-ip-3fe9">GCP Cloud Functions with a static IP</a></li>
<li><a href="https://gist.github.com/brokeyourbike/ee7c5ede900da6f31ced9fe587e0c706">Cloud Functions static outbound IP address</a></li>
<li><a href="https://stackoverflow.com/q/38811882">Possible to get static IP address for Google Cloud Functions?</a></li>
<li><a href="https://cloud.google.com/nat/docs/set-up-manage-network-address-translation">Set up and manage network address translation with Cloud NAT</a></li>
</ul>
<p>To add my own contribution, I‚Äôll share a <a href="https://www.pulumi.com/">Pulumi</a>
example to provision everything you need to get a static IP on your
Cloud Functions. It‚Äôll get you in the same place as the tutorials above.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">const</span> gcp = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;@pulumi/gcp&#x27;</span>)

<span class="hljs-keyword">const</span> subnet = <span class="hljs-keyword">new</span> gcp.<span class="hljs-property">compute</span>.<span class="hljs-title class_">Subnetwork</span>(<span class="hljs-string">&#x27;subnet&#x27;</span>, {
  <span class="hljs-attr">network</span>: <span class="hljs-string">&#x27;default&#x27;</span>,
   <span class="hljs-comment">// Arbitrary range that doesn&#x27;t conflict with other subnets in your VPC</span>
  <span class="hljs-attr">ipCidrRange</span>: <span class="hljs-string">&#x27;10.8.0.0/28&#x27;</span>
})

<span class="hljs-keyword">const</span> router = <span class="hljs-keyword">new</span> gcp.<span class="hljs-property">compute</span>.<span class="hljs-title class_">Router</span>(<span class="hljs-string">&#x27;router&#x27;</span>, {
  <span class="hljs-attr">network</span>: <span class="hljs-string">&#x27;default&#x27;</span>
})

<span class="hljs-keyword">const</span> ip1 = <span class="hljs-keyword">new</span> gcp.<span class="hljs-property">compute</span>.<span class="hljs-title class_">Address</span>(<span class="hljs-string">&#x27;ip-1&#x27;</span>, {})
<span class="hljs-keyword">const</span> ip2 = <span class="hljs-keyword">new</span> gcp.<span class="hljs-property">compute</span>.<span class="hljs-title class_">Address</span>(<span class="hljs-string">&#x27;ip-2&#x27;</span>, {})

<span class="hljs-keyword">new</span> gcp.<span class="hljs-property">compute</span>.<span class="hljs-title class_">RouterNat</span>(<span class="hljs-string">&#x27;nat&#x27;</span>, {
  <span class="hljs-attr">router</span>: router.<span class="hljs-property">name</span>,
  <span class="hljs-attr">region</span>: router.<span class="hljs-property">region</span>,

  <span class="hljs-attr">natIpAllocateOption</span>: <span class="hljs-string">&#x27;MANUAL_ONLY&#x27;</span>,
  <span class="hljs-attr">natIps</span>: [ip1.<span class="hljs-property">selfLink</span>, ip2.<span class="hljs-property">selfLink</span>],

  <span class="hljs-attr">sourceSubnetworkIpRangesToNat</span>: <span class="hljs-string">&#x27;LIST_OF_SUBNETWORKS&#x27;</span>,
  <span class="hljs-attr">subnetworks</span>: [
    {
      <span class="hljs-attr">name</span>: subnet.<span class="hljs-property">id</span>,
      <span class="hljs-attr">sourceIpRangesToNats</span>: [<span class="hljs-string">&#x27;ALL_IP_RANGES&#x27;</span>]
    }
  ],

  <span class="hljs-comment">// If not specified, Pulumi enables endpoint-independent mapping by default,</span>
  <span class="hljs-comment">// even though it&#x27;s not enabled by default when using the Google Cloud</span>
  <span class="hljs-comment">// console.</span>
  <span class="hljs-comment">//</span>
  <span class="hljs-comment">// To be in the same state as if we used the console, we explicitly</span>
  <span class="hljs-comment">// have to disable it here.</span>
  <span class="hljs-attr">enableEndpointIndependentMapping</span>: <span class="hljs-literal">false</span>

  <span class="hljs-comment">// More things to go here for optimal performance, see below</span>
})

<span class="hljs-keyword">new</span> gcp.<span class="hljs-property">vpcaccess</span>.<span class="hljs-title class_">Connector</span>(<span class="hljs-string">&#x27;connector&#x27;</span>, {
  <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;connector&#x27;</span>,
  <span class="hljs-attr">subnet</span>: {
    <span class="hljs-attr">name</span>: subnet.<span class="hljs-property">name</span>
  }
})
</code></pre>
<p>What this code does:</p>
<ol>
<li>Provision a <code>/28</code> subnet that is going to be used for the VPC
connector VMs, and that we‚Äôll attach the NAT to.</li>
<li>Create the Cloud Router necessary for the NAT to do its
configurational magic.</li>
<li>Allocate 2 static public IP addresses.</li>
<li>Create the Cloud NAT in manual mode with the IPs we just created, and
attach it to the VPC connector subnet.</li>
<li>Create the VPC connector in the subnet we prepared for it.</li>
</ol>
<p>Finally you can configure your Cloud Functions, Firebase Functions or
Cloud Run containers to use that VPC connector for all its traffic. In
the case of a Firebase Function, it looks like this:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">const</span> functions = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;firebase-functions&#x27;</span>)

functions.<span class="hljs-title function_">runWith</span>({
  <span class="hljs-attr">vpcConnector</span>: <span class="hljs-string">&#x27;connector&#x27;</span>,
  <span class="hljs-attr">vpcConnectorEgressSettings</span>: <span class="hljs-string">&#x27;ALL_TRAFFIC&#x27;</span>
})
  <span class="hljs-comment">// Your actual function, for example</span>
  .<span class="hljs-property">https</span>.<span class="hljs-title function_">onRequest</span>(<span class="hljs-keyword">async</span> (req, res) =&gt; {
    response.<span class="hljs-title function_">json</span>(<span class="hljs-keyword">await</span> (<span class="hljs-keyword">await</span> <span class="hljs-title function_">fetch</span>(<span class="hljs-string">&#x27;https://api.ipify.org?format=json&#x27;</span>)).<span class="hljs-title function_">json</span>())
  })
</code></pre>
<p>And ta-da, you get static IPs! üéâ</p>
<p>Everything seems to be working smoothly when you perform basic
connectivity testing (i.e. making a few requests to <a href="https://api.ipify.org"><code>api.ipify.org</code></a>),
so you pat yourself on the back ‚Äúnice, it wasn‚Äôt that bad after all‚Äù and
you go grab a beer.</p>
<p>Did you think you were done? Wait. We‚Äôre just getting started.</p>
<h2 id="when-the-trouble-start" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#when-the-trouble-start"><span>When the trouble start</span></a></h2>
<p>So you happily go on and deploy your Cloud NAT and VPC Connector. To
your staging environment, obviously, right? Right?</p>
<figure class="center">
  <img alt="Meme about deploying to staging" src="https://www.codejam.info/img/2023/03/to-staging-right.jpg">
</figure>
<p>But if you have some kind of traffic, you quickly notice something
wrong.</p>
<p>Your Cloud Functions‚Äô <strong>execution time</strong> is much higher than
usual (up to minutes instead of milliseconds), and as a side effect of
that, your <strong>instance count</strong> is likely higher than normal. On the VPC
Connector side, everything looks good. But on the Cloud NAT, you notice
a non-zero <strong>dropped sent packets rate</strong>, with <code>OUT_OF_RESOURCES</code> as a
reason.</p>
<p>Maybe you also have a non-zero <strong>dropped received packets rate</strong> but
that is probably not the concern here (<a href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#what-about-dropped-received-packets-rate">more on that later</a>).</p>
<p>So what is going on? <a href="https://cloud.google.com/nat/docs/monitoring#gateway_filtering_dimensions">The docs</a>
tell us that Cloud NAT is running out of NAT IP addresses or ports.</p>
<div class="note">
<p><strong>Note:</strong> if you used Pulumi (<a href="https://github.com/hashicorp/terraform-provider-google/issues/10609">or Terraform</a>)
without explicitly disabling endpoint-independent mapping, you might
have accidentally turned on <a href="https://cloud.google.com/nat/docs/ports-and-addresses#ports-reuse-endpoints">endpoint-independent mapping (EIM)</a>,
which wouldn‚Äôt have been on by default if you used the GCP console.</p>
<p>If you see dropped packets with reason <code>ENDPOINT_INDEPENDENT_CONFLICT</code>,
and you didn‚Äôt intend to enable endpoint-independent mapping, this is
your problem here. You probably want to disable it, or even to enable
<em>dynamic port allocation</em>.</p>
<p>In case you <em>do</em> need endpoint-independent mapping, <a href="https://cloud.google.com/nat/docs/troubleshooting#endpoint-independent-conflict">this section of the docs</a>
can help you troubleshoot this.</p>
</div>
<h2 id="fixing-nat-out-of-resources" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#fixing-nat-out-of-resources"><span>Fixing NAT out of resources</span></a></h2>
<p>Let‚Äôs say you assigned 2 NAT IPs. Each IP gives you
<a href="https://cloud.google.com/nat/docs/ports-and-addresses#ports">64,512</a>
ports to work with (65,536 minus the 1024 privileged ports). So we‚Äôre
working with a total of 129,024 ports available for NAT at a time.</p>
<p>If this looks a bit tight for your current traffic and network patterns,
there you go, you need to add more IPs.</p>
<p>But if you estimate that is is reasonable (or even <em>way, way enough</em>)
for your expected traffic, adding more IPs will likely not solve the
problem.</p>
<p>In our case with the <em>default</em> Cloud NAT configuration, it should be in
<a href="https://cloud.google.com/nat/docs/ports-and-addresses#static-port">static port allocation mode</a>,
aka the state it‚Äôs in if you don‚Äôt check ‚Äúdynamic port allocation‚Äù in
the <strong>advanced configurations</strong> part (hidden by default).</p>
<figure class="center">
  <img alt="Default Cloud NAT port allocation settings" srcset="../../img/2023/03/cloud-nat-port-allocation.png 2x">
</figure>
<p>What this reveals is one key piece of information. <strong>Our Cloud NAT
defaults to static port allocation with 64 ports per VM.</strong></p>
<p>The copy in this UI is misleading, because while it reads 64 ‚Äúminimum
ports per VM instance‚Äù, it is actually both a minimum <em>and</em> a maximum
(well, it‚Äôs <em>static</em>), which is why the ‚Äúmaximum ports‚Äù input is
disabled.</p>
<p><strong>So let‚Äôs say you configured your VPC Connector to use 2 VMs, this means
you‚Äôre artificially limiting your NAT to use a most 128 ports used at a
time!!</strong> (Out of your 129,024 available ports if you have 2 IPs. üòÖ)</p>
<p>No wonder when all the traffic of your Cloud Functions go through those
two poor VPC Connector VMs, you end up seeing huge network latency and
dropped packets.</p>
<div class="note">
<p><strong>Note:</strong> the number you care about here is really the number of VMs you
configured on the VPC Connector. You may have a much higher <em>instances
count</em> on your Cloud Functions side, but since their traffic has to go
through the VPC Connector instances first, it‚Äôs really this one that
matters.</p>
</div>
<p>Once we understand that, the fix becomes obvious: <strong>increase the number
of ports per VM</strong>.</p>
<p>Since in our example we have 2 VPC Connector VMs and 2 IP addresses,
assuming we use the Cloud NAT only for those, we could in theory assign
up to 65,536 ports (all of an IP‚Äôs ports) per VM!</p>
<p>Obviously adjust this number based on the maximum number of VMs you can
have relative to how many IPs you allocated.</p>
<p>Realistically, if you want to keep some headroom for adding more VPC
Connector VMs without adding more IPs in the future, you need to pick a
lower number like 4,096, 8,192, 16,384 or 32,768, especially if that‚Äôs
enough for your current needs.</p>
<p>The takeaway from is that the default Cloud NAT configuration is really
not adapted to be used with a VPC Connector, and we‚Äôre required to tune
the settings for proper network performance. It‚Äôs probably a decent
default for other use cases, but <em>definitely</em> not this one.</p>
<h2 id="going-further-with-dynamic-port-allocation" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#going-further-with-dynamic-port-allocation"><span>Going further with dynamic port allocation</span></a></h2>
<p>Increasing the static number of ports per VM should have helped quite a
bit with the latency and dropped packets, but we can do better.</p>
<p>If we enable <a href="https://cloud.google.com/nat/docs/ports-and-addresses#dynamic-port">dynamic port allocation</a>,
this will allow Cloud NAT to allocate even more ports to a given VM if
needed. It can use any number of ports between the min/max range you
configure, up to a maximum of 65,536 ports (a full IP).</p>
<p>An important thing to keep in mind with dynamic port allocation is that
when a VM uses all its pre-allocated ports and reaches the point where
it needs to allocate more more ports dynamically, <strong>this is not
instantaneous</strong>.</p>
<p>The symptoms of that would be, again, dropped packets and increased
latency while the ports are being allocated.</p>
<p>In our scenario, this would be very obvious if we used dynamic port
allocation with its default minimum ports per VM of 32 (when our load
needs orders of magnitude more ports than that).</p>
<p><strong>So we can‚Äôt rely solely on dynamic port allocation to save our day. We
do still need to configure a sensible minimum ports per VM <em>that matches
our expected needs</em>.</strong></p>
<p>Concretely, if we have 2 to 3 VPC Connector VMs, 2 NAT IPs, and the NAT
is solely used by the VPC Connector, using a dynamic port allocation
with a minimum ports per VM of 16,384 would be a good match that lives
us some headroom for adding a few more VMs without needing extra IPs.</p>
<h2 id="going-even-further-with-tcp-settings" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#going-even-further-with-tcp-settings"><span>Going even further with TCP settings</span></a></h2>
<p>The <strong>advanced configurations</strong> of Cloud NAT also gives us control over
various protocol timeouts. Here are the defaults:</p>
<figure class="center">
  <img alt="Default Cloud NAT timeouts settings" srcset="../../img/2023/03/cloud-nat-timeouts.png 2x">
</figure>
<p>Here we‚Äôll focus on the TCP settings. Here‚Äôs a more detailed description
of those from <a href="https://cloud.google.com/nat/docs/overview#specs-timeouts">the spec</a>:</p>
<ul>
<li><strong>TCP established connection idle timeout:</strong> specifies the time that a
connection is idle before the Cloud NAT mappings are removed.</li>
<li><strong>TCP transitory connection idle timeout:</strong> specifies the time that
TCP connections can remain in the <a href="https://en.wikipedia.org/wiki/TCP_half-open">half-open state</a>
before the Cloud NAT mappings can be deleted.</li>
<li><strong>TCP time wait:</strong> specifies the time that a
fully closed TCP connection is retained in the Cloud NAT mappings
after the connection expires.</li>
</ul>
<p>I‚Äôm not too concerned about half-open TCP connections, and keeping them
around for 30 seconds sounds like a reasonable value in the first place,
so we‚Äôll leave the <strong>transitory idle timeout</strong> alone.</p>
<p>For <strong>established idle timeout</strong> and <strong>TCP time wait</strong> though,
respective values of <strong>TWENTY MINUTES</strong> and 2 minutes may be more
problematic.</p>
<p>Those defaults are probably sensible when you have <em>actual</em> VMs
directly connecting through the NAT, but with the dynamic and
‚Äúserverless‚Äù nature of Cloud Functions, keeping idle and especially
closed connections around for that long is no good.</p>
<p><strong>Matching those with the value of your Cloud Functions request timeout
would make more sense</strong>, which may be as low as 60 or 30 seconds (or
even lower). Once a function gets killed because it exceeded its
timeout, there‚Äôs no point in keeping the TCP connections it opened (and
maybe failed to close) for any longer, especially not 20 minutes!</p>
<p>In my case, lowering those timeouts to 30 seconds had a noticeable
difference in the NAT <strong>open connections</strong> and port <strong>usage metric</strong>
(they got cut by half!).</p>
<h2 id="applying-this-to-our-pulumi-example" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#applying-this-to-our-pulumi-example"><span>Applying this to our Pulumi example</span></a></h2>
<p>After learning all this, we can go back to our initial <a href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#configuring-them-together">Pulumi example</a>
and apply those optimizations by adding the following to our <code>RouterNat</code>
configuration. <strong>Keep in mind this is tuned for 2 (min) to 3 (max) VPC
Connector VMs that are the <em>sole</em> VMs to use a Cloud NAT with 2 static IPs.</strong>
Tweak appropriately.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">new</span> gcp.<span class="hljs-property">compute</span>.<span class="hljs-title class_">RouterNat</span>(<span class="hljs-string">&#x27;nat&#x27;</span>, {
  <span class="hljs-comment">// ...</span>

  <span class="hljs-attr">enableDynamicPortAllocation</span>: <span class="hljs-literal">true</span>,
  <span class="hljs-attr">minPortsPerVm</span>: <span class="hljs-number">16384</span>,
  <span class="hljs-attr">maxPortsPerVm</span>: <span class="hljs-number">65536</span>,
  <span class="hljs-attr">tcpEstablishedIdleTimeoutSec</span>: <span class="hljs-number">60</span>,
  <span class="hljs-attr">tcpTimeWaitTimeoutSec</span>: <span class="hljs-number">60</span>
})
</code></pre>
<h2 id="what-about-dropped-received-packets-rate" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#what-about-dropped-received-packets-rate"><span>What about dropped received packets rate?</span></a></h2>
<p>After all this, we‚Äôre in a pretty good spot for our Cloud Functions to
go through Cloud NAT static IPs with optimal performance.</p>
<p>Yet, you might notice that your <a href="https://stackoverflow.com/q/72620834/4324668">dropped received packets</a>
metric in Cloud NAT is non-zero, and that may concern you.</p>
<p>My advice for you will be to look at the proportion of dropped received
packets compared to your total received packets.</p>
<p>While the Cloud NAT metrics tab shows you the dropped received packets
rate, you don‚Äôt get the total received packets rate there. You‚Äôll have
to go to GCP metrics explorer and look at <code>received_packets_count</code>.</p>
<p>If your dropped received packets rate is especially low compared to the
total received packets you‚Äôre processing (e.g. 0.01%), and you notice no
negative effects on your app (latency, errors or whatnot), you‚Äôre
probably fine. After all, those packets are packets that Cloud NAT could
not translate, which may include invalid or unauthorized traffic.</p>
<p>However if it‚Äôs affecting a non-negligible part of your traffic, and
if you‚Äôre noticing a high latency or network error rate, you definitely
need to address it. This will widely vary based on your specific context
and network patterns, but as a blind shot, if you underestimated how
long your Cloud Functions can be alive and you <a href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#going-even-further-with-tcp-settings">lowered the TCP timeouts</a>
too much, there‚Äôs probably some tuning to be done around there.</p>
<h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/03/cloud-functions-static-ip-nat.html#conclusion"><span>Conclusion</span></a></h2>
<p>If you made it here, congrats! This article was pretty dense, and we
covered a number of fairly complex topics. I hope you learnt everything
you needed in order to have a successful Cloud NAT configuration for
your serverless (or Kubernetes) environment.</p>
<p>If I made mistakes in this post, or if you found something of value that
would be worth adding there, as usual, <a href="https://www.codejam.info/val.html#contact">let me know</a>
and I‚Äôll be happy to make updates!</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Join the discussion on <a href="https://twitter.com/valeriangalliat/status/1636458334340390941">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>OVH email redirect causes SPF check failure</title>
    <link href="https://www.codejam.info/2023/02/ovh-email-redirect-spf-failure.html" />
    <id>https://www.codejam.info/2023/02/ovh-email-redirect-spf-failure.html</id>
    <updated>2023-02-26T05:00:00.000Z</updated>
    <content type="html"><![CDATA[<div class="note">
<p><strong>Note:</strong> I put OVH in the title but it could happen with any provider
that offers email redirects.</p>
</div>
<p>Let‚Äôs say you have an email address <code>foo@foo.com</code>, and you set up a
redirect with your provider so that it forwards all emails to
<code>foo@gmail.com</code>, which would be a common scenario to use Gmail with a
custom domain without paying for Google Workspace (using this as an
example but the problem is not directly related to Gmail).</p>
<p>In my case with OVH, this is configured in <code>foo@foo.com</code>'s MX plan,
under <a href="https://docs.ovh.com/ca/en/emails/email-redirection-guide/">manage redirections</a>.</p>
<p>It works well most of the time, <strong>except when a sender tells me they
failed to send me an email</strong>.</p>
<p>It could be someone sending me an email from, for example,
<code>bar@gmx.com</code>, who tells me (obviously via another mean) that their
email was returned, with a message similar to this:</p>
<blockquote>
<p><strong>Subject:</strong> Undelivered Mail Returned to Sender<br>
<strong>From:</strong> <code>MAILER-DAEMON@mo557.mail-out.ovh.net</code></p>
<p>This is the mail system at host <code>mo557.mail-out.ovh.net</code>.</p>
<p>I‚Äôm sorry to have to inform you that your message could not be
delivered to one or more recipients. It‚Äôs attached below.</p>
<p>For further assistance, please send mail to postmaster.</p>
<p>If you do so, please include this problem report. You can delete your
own text from the attached returned message.</p>
<p>The mail system</p>
<p><a href="mailto:foo@gmail.com">foo@gmail.com</a>: host gmail-smtp-in.l.google.com[66.102.1.27] said:
550-5.7.26 The MAIL FROM domain [gmx.com] has an SPF record with a
hard fail 550-5.7.26 policy (-all) but it fails to pass SPF checks
with the ip: 550-5.7.26 [46.105.33.1]. To best protect our users from
spam and phishing, the 550-5.7.26 message has been blocked. Please
visit 550-5.7.26 https://support.google.com/mail/answer/81126#authentication
for more 550 5.7.26 information.
h21-20020a05600c351500b003eb3caa4d08si2037016wmq.38 - gsmtp (in reply
to end of DATA command)</p>
</blockquote>
<div class="note">
<p><strong>Note:</strong> I use <a href="https://www.gmx.com/">GMX</a> as an example here because
it‚Äôs a sender domain that I was consistently getting SPF issues with
because of my redirect setup.</p>
</div>
<p>This doesn‚Äôt seem to be a very widely encountered problem, yet I could
find a few occurrences of it in the wild like on <a href="https://www.reddit.com/r/AnonAddy/comments/ju9vgc/ovh_mail_redirection_fails/">this Reddit post</a>
as well as those Google
<a href="https://support.google.com/mail/thread/175932116">support</a>
<a href="https://support.google.com/mail/thread/195729241">threads</a>
(in French, and sadly locked so I couldn‚Äôt post the solution there).</p>
<h2 id="the-issue" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/02/ovh-email-redirect-spf-failure.html#the-issue"><span>The issue</span></a></h2>
<p>What‚Äôs going wrong here? It turns out that the sender domain (in this
example, <code>gmx.com</code>) had configured a strict <a href="https://en.wikipedia.org/wiki/Sender_Policy_Framework">SPF policy</a>
that only allowed their own servers to deliver emails from <code>@gmx.com</code>
addresses.</p>
<p>We can check this running the following command:</p>
<pre><code class="hljs language-console"><span class="hljs-meta prompt_">$ </span><span class="language-bash">host -t TXT gmx.com | grep spf</span>
gmx.com descriptive text &quot;v=spf1 ip4:213.165.64.0/23 ip4:74.208.5.64/26 ip4:74.208.122.0/26 ip4:212.227.126.128/25 ip4:212.227.15.0/24 ip4:212.227.17.0/27 ip4:74.208.4.192/26 ip4:82.165.159.0/24 ip4:217.72.207.0/27 -all&quot;
</code></pre>
<div class="note">
<p><strong>Note:</strong> to be clear, this is not a bad thing. It‚Äôs totally legitimate
from GMX to only allow their own servers to deliver emails from
<code>@gmx.com</code> addresses!</p>
<p>The reason it doesn‚Äôt happen with most sender domains is that it‚Äôs
common to configure SPF with a ‚Äúsoft fail‚Äù (<code>~all</code>) instead of a ‚Äúhard
fail‚Äù (<code>-all</code>) like GMX does. See the difference <a href="https://knowledge.ondmarc.redsift.com/en/articles/1148885-spf-hard-fail-vs-spf-soft-fail">here</a>.</p>
<p>A soft fail would result in the email being delivered but potentially
being flagged as spam, whereas a hard fail gets downright rejected.</p>
</div>
<p>Since Gmail do check the origin sender SPF policy and enforces it, it
rejected the <code>@gmx.com</code> email being forwarded by my OVH relay.</p>
<p>If you want to learn more about this issue, <a href="https://support.tigertech.net/spf">this post from Tiger Technologies</a>
is a very good read.</p>
<h2 id="the-fix" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/02/ovh-email-redirect-spf-failure.html#the-fix"><span>The fix</span></a></h2>
<p>Sadly there‚Äôs no trivial fix for this. The post linked just above
mentions a few solutions in the last section but notes that they‚Äôre not
widely available and might cause other issues. Their conclusion is:
<strong>for now, we‚Äôd recommend simply not forwarding important mail to other
ISPs</strong>.</p>
<p>What can we do from there? Well in my case, I had to reverse the
relationship between my OVH address and Gmail: instead of my OVH address
forwarding emails to Gmail, I removed the redirect and <strong>configured
Gmail to fetch emails from my OVH address via POP3</strong>.</p>
<div class="note">
<p><strong>Note:</strong> this alternative method is not specific to OVH and Gmail. It
will work as long as:</p>
<ol>
<li>Your target email system supports fetching emails from other
addresses via IMAP or POP3.</li>
<li>The email hosting provider you use for your intermediary address
has IMAP or POP3 capabilities, not only redirects.</li>
</ol>
</div>
<p>In order to do this with Gmail, their guide on <a href="https://support.google.com/mail/answer/21289">checking emails from other accounts</a>.</p>
<p>And if your intermediary (redirect) address is on OVH, you can find the
proper POP3 settings to use on their configuration guide, either for
<a href="https://docs.ovh.com/fr/emails/mail-mutualise-guide-configuration-dun-e-mail-mutualise-ovh-sur-linterface-de-gmail/">OVH France</a> or
<a href="https://docs.ovh.com/ca/en/emails/gmail-configuration/">OVH Canada</a>. In
short, it‚Äôs:</p>
<table>
<thead>
<tr>
<th>Region</th>
<th>Host</th>
<th>Port</th>
</tr>
</thead>
<tbody>
<tr>
<td>France</td>
<td><code>ssl0.ovh.net</code></td>
<td>995</td>
</tr>
<tr>
<td>Canada</td>
<td><code>pop.mail.ovh.ca</code></td>
<td>995</td>
</tr>
</tbody>
</table>
<h2 id="the-downside" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/02/ovh-email-redirect-spf-failure.html#the-downside"><span>The downside</span></a></h2>
<p>The main downside of this solution is that instead of OVH <em>pushing</em>
mails to Gmail, Gmail has to <em>pull</em> them from OVH periodically.
Concretely, this means <strong>increased latency</strong>. Instead of receiving
emails right away, you‚Äôll have to wait until Gmail decides to fetch
emails from your external accounts.</p>
<p>There‚Äôs no clear rule on how often Gmail checks external accounts. It
seems to be proportional to how often you receive new emails: if you
often receive new emails, it‚Äôll check quite often, but if you receive
just a few messages per day, <strong>it can wait 10, 20 or even 30 minutes
between refreshes</strong>.</p>
<h2 id="forcing-gmail-to-refresh-external-accounts-more-often" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/02/ovh-email-redirect-spf-failure.html#forcing-gmail-to-refresh-external-accounts-more-often"><span>Forcing Gmail to refresh external accounts more often</span></a></h2>
<p>Looking into this I found quite a few smart tricks to get Gmail to check
your external accounts more often.</p>
<p>The first one is <a href="https://rakowski.pro/how-to-force-gmail-to-check-your-pop3-account-as-often-as-possible/">described in this post</a>,
and consists in configuring a server of yours to send you an email (on the
address you check via POP3) every minute or so. This way, Gmail will
notice you‚Äôre getting a lot of messages and will check more often.</p>
<p>To avoid your inbox getting flooded by those messages, you can simply
add a filter that puts them directly to the trash!</p>
<p>What if you don‚Äôt have a server handy to run this script? As described
in this <a href="https://lifehacker.com/increase-the-frequency-gmail-checks-your-other-email-ac-5580553">Lifehacker post</a>,
you can run the code as Google Apps Script on Google Sheets. That‚Äôs
pretty rad if you ask me. üòÇ</p>
<p>But what if you don‚Äôt want to write code at all? <a href="https://webapps.stackexchange.com/questions/1811/can-i-control-how-often-gmail-polls-pop3-accounts-for-incoming-mail#comment2919_2090">This Stack Exchange comment</a>
got you covered: just create a dummy Google Calendar event repeated every X
minutes, and set up an email reminder for this event. ü§Ø</p>
<h2 id="the-hybrid-approach" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/02/ovh-email-redirect-spf-failure.html#the-hybrid-approach"><span>The hybrid approach</span></a></h2>
<p>With OVH, there‚Äôs another option that allows you have the speed of the
redirect when it works, but still receive the messages even when there‚Äôs
an SPF rejection. The problem of this approach is that it will still
result in the ‚ÄúUndelivered Mail Returned to Sender‚Äù message being sent
to the sender in case SPF fails (even if you do get the email), which is
not ideal.</p>
<p>This solution consists in the OVH email redirect settings to ‚Äúkeep a
copy of the email at OVHcloud‚Äù. This option is only available during the
initial redirect creation and can‚Äôt be modified later on, so if you
initially configured it as ‚Äúdo not store a copy of the email‚Äù, you‚Äôll
need to delete your redirect and recreate it.</p>
<div class="note">
<p><strong>Note:</strong> creating a redirect that keeps a copy of the email on OVH
materializes as two redirect entries: one from source to source, and one from
source to destination.</p>
<p>For example, it‚Äôll show:</p>
<ul>
<li><code>foo@foo.com</code> to <code>foo@gmail.com</code></li>
<li><code>foo@foo.com</code> to <code>foo@foo.com</code></li>
</ul>
<p>Just noting that here because it can be confusing.</p>
</div>
<p>On top of that, you also configure Gmail to check your OVH emails via
POP3 <a href="https://www.codejam.info/2023/02/ovh-email-redirect-spf-failure.html#the-fix">as explained earlier</a>.</p>
<p>The result is that when the redirect works, you‚Äôll get your emails
instantly. When case the redirect fails, the message will still end up in
your OVH inbox, which Gmail will fetch eventually, so you‚Äôll still get
it that way.</p>
<p>But as I said, because the redirect failed, the sender will still
receive back an error email and believe that you didn‚Äôt receive their
email. I don‚Äôt know of a way to avoid that with this solution.</p>
<p>As for the messages that were successfully redirected, be assured that
<em>they won‚Äôt be duplicated</em>! Even though they will be fetched again when
Gmail refreshes the POP3 inbox, Gmail is able to tell that it‚Äôs the same
message that it already saw and will not show it to you twice. Neat.</p>
<h2 id="wrapping-up" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2023/02/ovh-email-redirect-spf-failure.html#wrapping-up"><span>Wrapping up</span></a></h2>
<p>In this post we explored the technical details of a common error that
happens when an email redirect conflicts with the origin SPF rules.</p>
<p>We saw that we can mitigate it under certain conditions, by reversing
the redirect relationship: instead of one email redirecting to another,
you need to have the second email checks the inbox of the former.</p>
<p>With Gmail, this can introduce unwanted latency, but there‚Äôs a few hacks
to work around that.</p>
<p>Finally we saw an hybrid approach that gets ‚Äúthe best of both worlds‚Äù,
except for the error message still being sent back‚Ä¶</p>
<p>What was your favorite option? Let me know on
<a href="https://twitter.com/valeriangalliat/status/1629899238728499200">Twitter</a>!</p>
<p>And if you know of other solutions I didn‚Äôt mention, please send me an
email! Even if you do strict SPF checks, don‚Äôt worry, I‚Äôll receive it. üòâ</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Join the discussion on <a href="https://twitter.com/valeriangalliat/status/1629899238728499200">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>GitHub: disable squash &amp; merge on specific branches</title>
    <link href="https://hookdeck.com/blog/post/building-chrome-extension-disable-squash-and-merge-github-branches" />
    <id>https://hookdeck.com/blog/post/building-chrome-extension-disable-squash-and-merge-github-branches</id>
    <updated>2022-08-15T04:00:00.000Z</updated>
  </entry>
  <entry>
    <title>Adobe Bridge mass update filetype associations</title>
    <link href="https://www.codejam.info/2022/07/adobe-bridge-mass-update-filetype-associations.html" />
    <id>https://www.codejam.info/2022/07/adobe-bridge-mass-update-filetype-associations.html</id>
    <updated>2022-07-19T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Bridge is a pretty powerful file explorer by Adobe, that
<a href="https://prodesigntools.com/free-adobe-bridge-cc.html">now ships for free since the 2022 version</a>.
Sweet.</p>
<p>But there‚Äôs always one thing that bugs me with it: it keeps opening
photos in Photoshop, and Photoshop is sloooooow to start. When I
double-click on a picture, I most often just want to see it in Preview.</p>
<h2 id="the-manual-solution" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/07/adobe-bridge-mass-update-filetype-associations.html#the-manual-solution"><span>The manual solution</span></a></h2>
<p>The solution, is to go in <kbd>Preferences</kbd>, <kbd>File Type
Associations</kbd> and associate pictures with Preview form there.</p>
<p>The problem is that there‚Äôs <em>countless</em> different extensions for
pictures and we need to update them one by one! Bummer.</p>
<figure class="center">
  <img alt="Bridge filetype associations" src="https://www.codejam.info/img/2022/07/bridge-preferences.png">
</figure>
<p>It would be fine if it only had to happen once, but on any new Bridge
installation, or even after a major update, it resets and I have to
start over.</p>
<h2 id="the-automated-solution" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/07/adobe-bridge-mass-update-filetype-associations.html#the-automated-solution"><span>The automated solution</span></a></h2>
<p>Luckily there‚Äôs a quick way to take everything that‚Äôs currently
associated to Photoshop and replace it with Preview!</p>
<p>First, we need to manually associate at least one filetype in the
previous dialog. This will make sure that Bridge creates the file
<code>~/Library/Application Support/Adobe/Bridge 2022/Adobe Bridge Opener Preferences.xml</code>,
where it stores the filetype associations.</p>
<p>From there, we can open it and using a text editor, replace every
occurrence of <code>Photoshop</code> with <code>/System/Applications/Preview.app</code>.</p>
<p>If you want a one-liner to paste, this can even be done with <code>sed</code>:</p>
<pre><code class="hljs language-sh">sed -i <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-string">&#x27;s,&quot;Photoshop&quot;,&quot;/System/Applications/Preview.app&quot;,g&#x27;</span> ~/Library/Application\ Support/Adobe/Bridge\ 2022/Adobe\ Bridge\ Opener\ Preferences.xml
</code></pre>
<p>After that, just restart Bridge and don‚Äôt ever be scared of a file
randomly opening in Photoshop again!</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Start a conversation on <a href="https://twitter.com/valeriangalliat">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Empty body vs. no body in HTTP/2</title>
    <link href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html" />
    <id>https://www.codejam.info/2022/06/empty-body-no-body-http2.html</id>
    <updated>2022-06-01T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p><abbr title="Today I learnt">TIL</abbr> there‚Äôs a (subtle) difference
in HTTP/2 between sending an empty body, and sending no body at all.</p>
<p>In this post we‚Äôll look at <strong>how that can happen</strong>, how to <strong>test it
with cURL</strong>, and the <strong>subtleties of HTTP/2</strong> that make this distinction
possible.</p>
<p>But as usual, I‚Äôll start by telling you the story of how I ended up with
such a hairy bug again <em>(I‚Äôm really, really good at getting myself in
this kind of fucked up situations for some reason)</em>.</p>
<h2 id="cloudflare-workers-and-the-content-length-header" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html#cloudflare-workers-and-the-content-length-header"><span>Cloudflare Workers and the <code>Content-Length</code> header</span></a></h2>
<p>At <a href="https://hookdeck.com/">Hookdeck</a>, we work heavily with <a href="https://workers.cloudflare.com/">Cloudflare
Workers</a>. And we also work heavily with
HTTP payloads.</p>
<p>One thing we asserted in the past, while it doesn‚Äôt seem to be
officially documented, is that Cloudflare computes the <code>Content-Length</code>
header if necessary before hitting the worker.</p>
<p>For example when sending a HTTP/1.1 <code>Transfer-Encoding: chunked</code> payload
(typically not including <code>Content-Length</code>), Cloudflare <strong>buffers the
whole body</strong> and sets the <code>Content-Length</code> header before calling the
worker, despite that header not being set by the client!</p>
<p>We observe a similar behavior in HTTP/2 (whose <code>DATA</code> frames
<a href="https://stackoverflow.com/questions/62439557/are-chunk-extensions-supported-by-http-2-and-if-so-how">resemble chunked encoding quite a bit</a>),
when the client omits the <code>Content-Length</code> header.</p>
<div class="note">
<p><strong>Note:</strong> even if we send a payload with an invalid <code>Content-Length</code>
(e.g. claiming a size much smaller than what we actually send),
Cloudflare catches it and refuses the request!</p>
</div>
<p>This is especially useful: because of that observation, we can actually
trust the <code>Content-Length</code> header, and rely on it to decide what to do
next in the worker.</p>
<h2 id="the-mysterious-requests-without-content-length" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html#the-mysterious-requests-without-content-length"><span>The mysterious requests without <code>Content-Length</code></span></a></h2>
<p>How then, during an incident response, do I find myself dealing with
<code>POST</code> requests that manifestly don‚Äôt have a <code>Content-Length</code> header?</p>
<p>My blind guess was to look at empty payloads. It‚Äôs the only edge case I
could think of that could, maybe, in some cases, result in Cloudflare
not enforcing a <code>Content-Length</code> header.</p>
<p>At first, I try the following:</p>
<pre><code class="hljs language-sh">curl https://events.hookdeck.com/e/source-id-goes-here \
  -X POST \
  -H <span class="hljs-string">&#x27;Content-Type: text/plain&#x27;</span> \
  --data <span class="hljs-string">&#x27;&#x27;</span> \
  --verbose
</code></pre>
<p>But I notice in the verbose logs that cURL nicely computed and sent
<code>Content-Length: 0</code>. Luckily we can turn that off by passing an empty
<code>Content-Length</code> header (which makes cURL omit the header altogether in
its request):</p>
<pre><code class="hljs language-sh">curl https://events.hookdeck.com/e/source-id-goes-here \
  -X POST \
  -H <span class="hljs-string">&#x27;Content-Type: text/plain&#x27;</span> \
  -H <span class="hljs-string">&#x27;Content-Length:&#x27;</span> \
  --data <span class="hljs-string">&#x27;&#x27;</span> \
  --verbose
</code></pre>
<p>But somehow, Cloudflare is still able to catch this and forces a
<code>Content-Length: 0</code> to be passed to my worker.</p>
<p>I try something else, which in my understanding <em>should</em> be the same
thing (omitting the <code>--data</code> parameter altogether):</p>
<pre><code class="hljs language-sh">curl https://events.hookdeck.com/e/source-id-goes-here \
  -X POST \
  -H <span class="hljs-string">&#x27;Content-Type: text/plain&#x27;</span> \
  --verbose
</code></pre>
<p>To my surprise, although the verbose logs from cURL look <em>identical</em>,
<strong>this results in the request hitting my worker without a
<code>Content-Length</code> header</strong>, bypassing Cloudflare‚Äôs ‚Äúenforcement‚Äù. Bingo!</p>
<p>This is a good step forward, but I‚Äôm even more confused. To my knowledge
those two commands <em>should</em> result in the exact same HTTP requests over
the wire. ü§î</p>
<div class="note">
<p><strong>Note:</strong> at that point I had a confirmation that having no
<code>Content-Length</code> header here was, in fact, possible (in the case of some
obscure empty payloads that are different from ‚Äúnormal‚Äù empty payloads
<em>somehow</em>).</p>
<p>I went on and made sure that the code could handle that, but I wasn‚Äôt
exactly <em>satisfied</em>. The <em>‚Äúsomehow‚Äù</em> part of my previous sentence was
itching me in a particular manner.</p>
</div>
<h2 id="digging-deeper-with-trace" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html#digging-deeper-with-trace"><span>Digging deeper with <code>--trace</code></span></a></h2>
<p>I tried adding <code>--trace</code>, and <code>--trace-ascii</code> to the previous cURL
commands, in order to dump the raw protocol data and compare it:</p>
<pre><code class="hljs language-diff"> curl https://events.hookdeck.com/e/source-id-goes-here \
   -X POST \
   -H &#x27;Content-Type: text/plain&#x27; \
   -H &#x27;Content-Length:&#x27; \
<span class="hljs-deletion">-  --data &#x27;&#x27;</span>
<span class="hljs-addition">+  --data &#x27;&#x27; \</span>
<span class="hljs-addition">+  --trace empty-body.txt</span>
 
 curl https://events.hookdeck.com/e/source-id-goes-here \
   -X POST \
<span class="hljs-deletion">-  -H &#x27;Content-Type: text/plain&#x27;</span>
<span class="hljs-addition">+  -H &#x27;Content-Type: text/plain&#x27; \</span>
<span class="hljs-addition">+  --trace no-body.txt</span>
</code></pre>
<p>Then diffing it with:</p>
<pre><code class="hljs language-sh">git diff --no-index empty-body.txt no-body.txt
</code></pre>
<p>(I like the output of <code>git diff</code> more than plain old
<a href="https://linux.die.net/man/1/diff"><code>diff(1)</code></a>.)</p>
<p>But this shows no relevant differences. Only the ‚ÄúSSL data‚Äù bits change,
but those are unintelligible. It otherwise appears that cURL sends
<em>exactly</em> the same thing.</p>
<p>How in hell could Cloudflare distinguish those two different yet
identical cURL invocations? <em>Hint: probably in the unintelligible
bits‚Ä¶</em></p>
<h2 id="what-about-http-1-1" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html#what-about-http-1-1"><span>What about HTTP/1.1</span></a></h2>
<p>So far, cURL defaulted to use HTTP/2, which is great. Maybe it‚Äôs a
HTTP/2-specific thing? (I know, I kinda spoiled it in the title of this
post.)</p>
<p>I add <code>--http1.1</code> to the earlier cURL commands to try: both requests
don‚Äôt have the <code>Content-Length</code> header after going through Cloudflare.
Interesting.</p>
<p>So there‚Äôs absolutely no difference between ‚Äúno data‚Äù and ‚Äúempty body‚Äù
in HTTP/1.1, which makes a lot of sense based on my understanding of the
HTTP protocol. There‚Äôs, finally, some sanity in this world.</p>
<p>So my quest is now to figure <strong>how the f*** is Cloudflare able to
distinguish between ‚Äúno body‚Äù and ‚Äúempty body‚Äù in HTTP/2 specifically</strong>.</p>
<div class="note">
<p><strong>Note:</strong> the attentive reader might have noticed that there‚Äôs virtually
no business value in answering that question.</p>
<p>I already knew a few ways to trigger an undefined <code>Content-Length</code> header,
and that was enough information for me to fix the bug and replay
whatever requests needed to.</p>
<p>At that point I‚Äôm only trying to quench my thirst of knowledge for sheer
pleasure.</p>
</div>
<h2 id="making-a-poc-in-c" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html#making-a-poc-in-c"><span>Making a PoC in C</span></a></h2>
<p>I decide to go a bit lower level and instead of using the cURL command,
I make a C program using <code>libcurl</code> to try and reproduce that behavior.</p>
<pre><code class="hljs language-c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;curl/curl.h&gt;</span></span>

<span class="hljs-type">int</span> <span class="hljs-title function_">main</span> <span class="hljs-params">(<span class="hljs-type">void</span>)</span> {
    curl_global_init(CURL_GLOBAL_ALL);

    CURL *curl = curl_easy_init();

    curl_easy_setopt(curl, CURLOPT_URL, <span class="hljs-string">&quot;https://events.hookdeck.com/e/source-id-goes-here&quot;</span>);
    curl_easy_setopt(curl, CURLOPT_HTTP_VERSION, CURL_HTTP_VERSION_2TLS);
    curl_easy_setopt(curl, CURLOPT_VERBOSE, <span class="hljs-number">1</span>);

    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">curl_slist</span> *<span class="hljs-title">list</span> =</span> <span class="hljs-literal">NULL</span>;

    <span class="hljs-built_in">list</span> = curl_slist_append(<span class="hljs-built_in">list</span>, <span class="hljs-string">&quot;Content-Type: text/plain&quot;</span>);
    <span class="hljs-built_in">list</span> = curl_slist_append(<span class="hljs-built_in">list</span>, <span class="hljs-string">&quot;Content-Length:&quot;</span>);

    curl_easy_setopt(curl, CURLOPT_HTTPHEADER, <span class="hljs-built_in">list</span>);

    <span class="hljs-comment">// Empty body</span>
    curl_easy_setopt(curl, CURLOPT_POSTFIELDS, <span class="hljs-string">&quot;&quot;</span>);

    <span class="hljs-comment">// No body</span>
    <span class="hljs-comment">// curl_easy_setopt(curl, CURLOPT_CUSTOMREQUEST, &quot;POST&quot;);</span>

    curl_easy_perform(curl);

    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<p>Here, the <code>CURLOPT_POSTFIELDS</code> method will result in the ‚Äúempty body‚Äù
path (where Cloudflare can set <code>Content-Length: 0</code> by itself), while
the ‚Äúno body‚Äù version will let the request go through all the way
without <code>Content-Length</code>.</p>
<p>It can be compiled and run with:</p>
<pre><code class="hljs language-sh">gcc test.c -o <span class="hljs-built_in">test</span> -lcurl
./test
</code></pre>
<p>But this repro doesn‚Äôt really lead me anywhere. This is not
low-level enough.</p>
<h2 id="digging-even-deeper-with-netcat" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html#digging-even-deeper-with-netcat"><span>Digging even deeper with netcat</span></a></h2>
<p>If I can‚Äôt find on the client side what distinguishes those requests,
let‚Äôs analyze the server side.</p>
<p>My first bet is to use <a href="https://linux.die.net/man/1/nc"><code>nc(1)</code></a>
(netcat) in listen mode and send my two <code>curl</code> requests to it. Then I‚Äôll
be able to see the raw data sent by cURL the underlying socket and
hopefully tell them apart:</p>
<pre><code class="hljs language-sh">nc -l -k -p 8888
</code></pre>
<p>(This makes netcat listen on port 8888: <code>-l</code> to listen, <code>-k</code> to keep
listening after the first connection, and <code>-p</code> to specify the port.)</p>
<p>Then I can hit it:</p>
<pre><code class="hljs language-diff"><span class="hljs-deletion">-curl https://events.hookdeck.com/e/source-id-goes-here \</span>
<span class="hljs-addition">+curl http://localhost:8888/ \</span>
   -X POST \
   -H &#x27;Content-Type: text/plain&#x27; \
   -H &#x27;Content-Length:&#x27; \
   --data &#x27;&#x27;
 
<span class="hljs-deletion">-curl https://events.hookdeck.com/e/source-id-goes-here \</span>
<span class="hljs-addition">+curl http://localhost:8888/ \</span>
   -X POST \
   -H &#x27;Content-Type: text/plain&#x27;
</code></pre>
<p>Sadly this results in the same HTTP/1.1 request in both cases:</p>
<pre><code class="hljs language-http"><span class="hljs-keyword">POST</span> <span class="hljs-string">/</span> <span class="hljs-meta">HTTP/1.1</span>
<span class="hljs-attribute">Host</span><span class="hljs-punctuation">: </span>localhost:8888
<span class="hljs-attribute">User-Agent</span><span class="hljs-punctuation">: </span>&lt;3
<span class="hljs-attribute">Accept</span><span class="hljs-punctuation">: </span>*/*
<span class="hljs-attribute">Content-Type</span><span class="hljs-punctuation">: </span>text/plain

</code></pre>
<p>(Yes <a href="https://github.com/valeriangalliat/dotfiles/blob/40ca54c1d6fdfca33e8dcc4e56807f9bf060de8e/net/curlrc#L1">my user agent is a heart in ASCII</a>,
what r u gonna do?)</p>
<p>And adding the <code>--http2</code> flag makes cURL ask for an upgrade to HTTP/2,
but can‚Äôt just send its HTTP/2 traffic right through:</p>
<pre><code class="hljs language-http"><span class="hljs-keyword">POST</span> <span class="hljs-string">/</span> <span class="hljs-meta">HTTP/1.1</span>
<span class="hljs-attribute">Host</span><span class="hljs-punctuation">: </span>localhost:8888
<span class="hljs-attribute">User-Agent</span><span class="hljs-punctuation">: </span>&lt;3
<span class="hljs-attribute">Accept</span><span class="hljs-punctuation">: </span>*/*
<span class="hljs-attribute">Connection</span><span class="hljs-punctuation">: </span>Upgrade, HTTP2-Settings
<span class="hljs-attribute">Upgrade</span><span class="hljs-punctuation">: </span>h2c
<span class="hljs-attribute">HTTP2-Settings</span><span class="hljs-punctuation">: </span>AAMAAABkAAQCAAAAAAIAAAAA
<span class="hljs-attribute">Content-Type</span><span class="hljs-punctuation">: </span>text/plain

</code></pre>
<p>Looks like some <em>negotiation</em> needs to happen prior to using HTTP/2.
Bummer.</p>
<h2 id="making-a-http-2-server-with-nodes-js" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html#making-a-http-2-server-with-nodes-js"><span>Making a HTTP/2 server with Nodes.js</span></a></h2>
<p>If we can‚Äôt <em>netcat</em> our way out of this, let‚Äôs make a real HTTP/2
server with Node.js.</p>
<p>First we‚Äôll generate a TLS key and certificate for <code>localhost</code> because
it appears that the HTTP/2 negotiation happens over TLS. Although it
doesn‚Äôt seem that the HTTP/2 spec <em>requires</em> TLS per se, I couldn‚Äôt make
it work without.</p>
<pre><code class="hljs language-sh">openssl req -x509 -newkey rsa:2048 -nodes -subj <span class="hljs-string">&#x27;/CN=localhost&#x27;</span> -keyout key.pem -out cert.pem
</code></pre>
<div class="note">
<p><strong>Note:</strong> in this command, <code>-nodes</code> <a href="https://stackoverflow.com/a/5087138/4324668">means ‚Äúno DES‚Äù and not ‚Äúnodes‚Äù</a>
and is used to leave the private key unencrypted. Without it, OpenSSL
will prompt for a passphrase.</p>
<p>Also the <code>-subj</code> argument is required otherwise OpenSSL will prompt for
all the certificate fields.</p>
</div>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> http2 <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;node:http2&#x27;</span>
<span class="hljs-keyword">import</span> fs <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;node:fs/promises&#x27;</span>

<span class="hljs-keyword">const</span> server = http2.<span class="hljs-title function_">createSecureServer</span>({
  <span class="hljs-attr">key</span>: <span class="hljs-keyword">await</span> fs.<span class="hljs-title function_">readFile</span>(<span class="hljs-string">&#x27;key.pem&#x27;</span>),
  <span class="hljs-attr">cert</span>: <span class="hljs-keyword">await</span> fs.<span class="hljs-title function_">readFile</span>(<span class="hljs-string">&#x27;cert.pem&#x27;</span>)
})

server.<span class="hljs-title function_">on</span>(<span class="hljs-string">&#x27;stream&#x27;</span>, <span class="hljs-function">(<span class="hljs-params">stream, headers, flags, rawHeaders</span>) =&gt;</span> {
  <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(flags, rawHeaders)

  stream.<span class="hljs-title function_">respond</span>({
    <span class="hljs-string">&#x27;:status&#x27;</span>: <span class="hljs-number">200</span>,
    <span class="hljs-string">&#x27;content-type&#x27;</span>: <span class="hljs-string">&#x27;text/plain&#x27;</span>
  })

  stream.<span class="hljs-title function_">end</span>(<span class="hljs-string">&#x27;Hello&#x27;</span>)
})

server.<span class="hljs-title function_">listen</span>(<span class="hljs-number">8888</span>)
</code></pre>
<p>For each new HTTP/2 stream, this server will log the
<a href="https://nodejs.org/api/http2.html#event-stream">‚Äúassociated flags‚Äù</a> as
well as the raw headers, in the hope to find the key difference there.</p>
<p>As before, we hit it, with the addition of <code>--insecure</code> because we don‚Äôt
want cURL to reject our self-signed certificate:</p>
<pre><code class="hljs language-diff"> curl http://localhost:8888/ \
   -X POST \
   -H &#x27;Content-Type: text/plain&#x27; \
   -H &#x27;Content-Length:&#x27; \
<span class="hljs-deletion">-  --data &#x27;&#x27;</span>
<span class="hljs-addition">+  --data &#x27;&#x27; \</span>
<span class="hljs-addition">+  --insecure</span>
 
 curl http://localhost:8888/ \
   -X POST \
<span class="hljs-deletion">-  -H &#x27;Content-Type: text/plain&#x27;</span>
<span class="hljs-addition">+  -H &#x27;Content-Type: text/plain&#x27; \</span>
<span class="hljs-addition">+  --insecure</span>
</code></pre>
<p>And while the raw headers are exactly the same, the flag is different:
in the first case (empty body) it‚Äôs set to <strong>4</strong>, while for the second
one (no body) it‚Äôs <strong>5</strong>. Bingo!</p>
<p>So what are those flags about anyway? The <a href="https://nodejs.org/api/http2.html#event-stream">Node.js documentation</a>
doesn‚Äôt say much‚Ä¶</p>
<blockquote>
<p><code>flags</code> <code>&lt;number&gt;</code> The associated numeric flags.</p>
</blockquote>
<h2 id="understanding-the-http-2-flags" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html#understanding-the-http-2-flags"><span>Understanding the HTTP/2 flags</span></a></h2>
<p>We get a hint of the available flags in <code>http2.constants</code>:</p>
<pre><code class="hljs language-js"><span class="hljs-title class_">Object</span>.<span class="hljs-title function_">keys</span>(http2.<span class="hljs-property">constants</span>)
  .<span class="hljs-title function_">filter</span>(<span class="hljs-function"><span class="hljs-params">name</span> =&gt;</span> name.<span class="hljs-title function_">includes</span>(<span class="hljs-string">&#x27;_FLAG_&#x27;</span>))
  .<span class="hljs-title function_">map</span>(<span class="hljs-function"><span class="hljs-params">name</span> =&gt;</span> <span class="hljs-string">`<span class="hljs-subst">${name}</span>: <span class="hljs-subst">${http2.constants[name]}</span>`</span>)
  .<span class="hljs-title function_">join</span>(<span class="hljs-string">&#x27;\n&#x27;</span>)
</code></pre>
<pre><code class="hljs">NGHTTP2_FLAG_NONE: 0
NGHTTP2_FLAG_END_STREAM: 1
NGHTTP2_FLAG_END_HEADERS: 4
NGHTTP2_FLAG_ACK: 1
NGHTTP2_FLAG_PADDED: 8
NGHTTP2_FLAG_PRIORITY: 32
</code></pre>
<p>We‚Äôre in the presence of bitwise flags. Let‚Äôs ‚Äúflatten‚Äù all of that in
binary, and pad them with zeroes up to 5 digits for display. This can be
done with:</p>
<pre><code class="hljs language-js">(number).<span class="hljs-title function_">toString</span>(<span class="hljs-number">2</span>).<span class="hljs-title function_">padStart</span>(<span class="hljs-number">5</span>, <span class="hljs-number">0</span>)
</code></pre>
<p>(Parentheses around <code>number</code> required when putting a literal number in
there.)</p>
<p>This gives us:</p>
<pre><code class="hljs">00100 (4) empty body
00101 (5) no body
</code></pre>
<p>And the <code>http2.constants</code> flags:</p>
<pre><code class="hljs">00000 (0) NGHTTP2_FLAG_NONE
00001 (1) NGHTTP2_FLAG_END_STREAM
00100 (4) NGHTTP2_FLAG_END_HEADERS
00001 (1) NGHTTP2_FLAG_ACK
01000 (8) NGHTTP2_FLAG_PADDED
10000 (32) NGHTTP2_FLAG_PRIORITY
</code></pre>
<p>Here we can clearly see that ‚Äúempty body‚Äù is just the <code>END_HEADERS</code>
flag, whereas ‚Äúno body‚Äù is a combination of <code>END_HEADERS</code> <em>and</em>
<code>END_STREAM</code>.</p>
<p>This is what makes Cloudflare behave in two different ways based on
those cURL requests!</p>
<p>If we go to <a href="https://datatracker.ietf.org/doc/html/rfc7540">the HTTP/2 RFC</a>
we get extra information in <a href="https://datatracker.ietf.org/doc/html/rfc7540#section-6.2">section 6.2</a>:</p>
<blockquote>
<p><code>END_STREAM</code> (0x1): When set, bit 0 indicates that the header block
is the last that the endpoint will send for the identified stream.</p>
<p><code>END_HEADERS</code> (0x4): When set, bit 2 indicates that this frame
contains an entire header block and is not followed by any
<code>CONTINUATION</code> frames.</p>
</blockquote>
<h2 id="in-short" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html#in-short"><span>In short</span></a></h2>
<p>While in HTTP/1.1 a request with no body (<code>curl -X POST</code>) is strictly
equivalent to a request with an empty body (<code>curl -X POST --data ''</code>),
there‚Äôs a subtle difference when using HTTP/2:</p>
<p>A ‚Äúno body‚Äù requests sets the <code>END_HEADERS &amp; END_STREAM</code> flags on the
HTTP/2 stream, whereas an ‚Äúempty body‚Äù will result in only <code>END_HEADERS</code>
(at least in the cURL implementation).</p>
<p>This can lead to those requests being treated slightly differently,
especially when they don‚Äôt include a <code>Content-Length</code> header. In the
case of Cloudflare Workers, here‚Äôs a table of <strong>whether or not
Cloudflare computed the <code>Content-Length</code> header for us</strong> despite not
being set by the client:</p>
<table>
<thead>
<tr>
<th>Request</th>
<th>HTTP/1.1</th>
<th>HTTP/2</th>
</tr>
</thead>
<tbody>
<tr>
<td>non-empty body (chunked)</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>non-empty body (not chunked)</td>
<td>Illegal</td>
<td>Body is always ‚Äúchunked‚Äù in HTTP/2</td>
</tr>
<tr>
<td>empty body</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>no body</td>
<td>No</td>
<td>No</td>
</tr>
</tbody>
</table>
<div class="note">
<p><strong>Note:</strong> in the case of the <code>POST</code> body lacking <code>Content-Length</code> and
<code>Transfer-Encoding: chunked</code>, this is effectively <a href="https://stackoverflow.com/questions/14758729/http-post-content-length-header-required">forbidden</a>
in HTTP/1.1.</p>
<p>Cloudflare still accepts those requests, but the <code>Content-Length</code> header
will definitely not be set, and the worker will see the body as being
empty (despite the client sending actual data).</p>
<p>Not really supposed to happen but good to know.</p>
</div>
<h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/06/empty-body-no-body-http2.html#conclusion"><span>Conclusion</span></a></h2>
<p>This was a fun issue to dig into. It wasn‚Äôt necessary to go that deep in
the rabbit hole, but it was definitely a fun challenge, plus it made me
learnt quite a bit about HTTP/2 which I wasn‚Äôt really up-to-date with.</p>
<p>I hope you enjoyed the read. Stay curious! ü§ô</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Join the discussion on <a href="https://twitter.com/valeriangalliat/status/1532007358225862657">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Best GoPro mount position for skiing</title>
    <link href="https://www.codejam.info/2022/05/best-gopro-position-skiing.html" />
    <id>https://www.codejam.info/2022/05/best-gopro-position-skiing.html</id>
    <updated>2022-05-25T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>After a long journey figuring how to <a href="https://www.codejam.info/2022/05/gopro-canadian-winter.html">prevent my GoPro HERO5 from dying in cold weather</a>
(so basically, during all of the ski season üôÑ), it was time for me to
find the best mount point for recording POV skiing videos!</p>
<h2 id="helmet-top" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/best-gopro-position-skiing.html#helmet-top"><span>Helmet top</span></a></h2>
<p>This is what seems to be the most common place to mount a GoPro for
winter sports. Still, there‚Äôs many ways to mount a GoPro on top of a
helmet, and it will vary on the kind of helmet you have, and how much
you‚Äôre willing to trade convenience for better video quality.</p>
<p>The shape of your helmet might not allow you to stick a GoPro mount
anywhere, because of vents (and the switch to open or close them), and
shape variations like insets and other non-smooth cuts. So you might not
have that much choice for a solid mount.</p>
<p>If you do though, here‚Äôs the tradeoffs:</p>
<ul>
<li>
<p>If you mount it <strong>at the frontmost part</strong>, you‚Äôre going to get a more
immersive point of view, but the GoPro will be in the way of your
goggles, so you can‚Äôt put them up on your helmet while the GoPro is
mounted there. Not super convenient.</p>
<p>Also I found that this was putting quite a bunch of weight towards the
front of my helmet and it was constantly pushing it down. The pressure
around my nose was a bit uncomfortable and most importantly, it kept
slipping down as I was skiing, especially during big shocks. You might
get better results depending on your helmet/goggles combination, but
it wasn‚Äôt very successful for me.</p>
</li>
<li>
<p>If you put it <strong>fully on top</strong>, it will be more balanced while skiing
(although I still have the same slipping issue as before, to a lesser
extent), but the point of view will be a bit high. You don‚Äôt see the
skis as much, and if you point it down too much, you will start seeing
a bit of the helmet at the bottom of the frame.</p>
</li>
<li>
<p>Somewhere <strong>in between</strong>, you should still have the option to put your
goggles up on your helmet without bothering the GoPro. The point of
view is not bad, although you might risk seeing a bit of the helmet at
the bottom of the frame. It will still put most of the weight on the
front of the helmet so that might be an issue for comfort depending on
your gear.</p>
</li>
</ul>
<p>With the GoPro on top of the helmet, it‚Äôs also more prone to taking the
wind, which can get tiring for your neck after a while.</p>
<p>One of the best advantages of a helmet-mounted GoPro is that it moves
with your face! Meaning that when you look one way or another, the
camera will follow you, making it easy to show action happening left and
right.</p>
<p>The problem is that it will <em>always</em> move with your head, including when
you check your surroundings and behind you before changing directions.
For me, this happens much more often than when I want to show on camera
something that‚Äôs not in front of me. And those quick pans are not
usually desirable.</p>
<h2 id="helmet-side" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/best-gopro-position-skiing.html#helmet-side"><span>Helmet side</span></a></h2>
<p>I loved that point of view <a href="https://youtu.be/o0Y1C88BhdY">on my motorcycle helmet</a>.
You can get the GoPro exactly at your eye level which gives one of the
best POV styles in my opinion, although the side of the helmet might be
in the frame, and you‚Äôll see the ‚Äúclear‚Äù side wider than the helmet
side.</p>
<p>From my motorcycle experience with a side mount, it was definitely not
as tiring for the neck than a top mount is. Seems that my neck is
stronger for compensating horizontal rotation than vertical inclination.
üòÜ</p>
<p>But the biggest problem in the case of a ski helmet is that a side mount
will be <strong>in the way of the strap of your goggles</strong>!</p>
<p>Depending on the shape of your helmet you might find a way to make this
work, but I couldn‚Äôt manage it on my own helmet. Too bad.</p>
<h2 id="chest-mount" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/best-gopro-position-skiing.html#chest-mount"><span>Chest mount</span></a></h2>
<p>When I found <a href="https://youtu.be/pXfNA-xqETA">this video</a> after hours
(days‚Ä¶) of research about <a href="https://www.codejam.info/2022/05/gopro-canadian-winter.html">how to keep the GoPro alive in cold temperature</a>,
they also mentioned their chest mount setup.</p>
<p>It‚Äôs something that was quite new to me, I‚Äôve seen very little chest
mount ski videos online in the past, and I really liked the look. So I
<a href="https://amzn.to/3sXrOcR">got one for myself</a>.</p>
<p>It‚Äôs a bit lower so you can see the skis really well, while still having
the whole landscape in the frame. You also see a bit the hands with the
poles on the sides and that‚Äôs quite a cool view. You can even see the
knees at rare occasions e.g. on really bumpy parts.</p>
<p>Overall, I find it <strong>even more immersive</strong> than a helmet mount!</p>
<p>But because it‚Äôs chest mounted, <strong>you can‚Äôt as easily turn to the
sides</strong> to show some action happening around, you‚Äôll always see pretty
much just what‚Äôs in front where your body is facing. You can try turning
your chest a bit to the sides but the effect is very limited compared to
turning your head.</p>
<p>It‚Äôs not something that I need a lot, so no big deal for me. Actually it
can even be seen as <strong>a feature</strong>: you can freely look around while
skiing without worrying about the camera moving in all directions and
making you nauseous when you watch it!</p>
<p>The chest mount gives more stable results than a helmet mount especially
on really shaky and bumpy slopes, and in the end I find the chest mount
footage smoother and more enjoyable to watch.</p>
<p>But the biggest thing for me was that the chest mount is <strong>really
comfortable</strong>. Having the extra weight of the GoPro on my chest makes
little to no difference. I can ski with a chest mount GoPro all day
without even noticing it‚Äôs there!</p>
<p>It‚Äôs also easier to take off and on from its mount because it‚Äôs right in
front of you and you can see it. When it‚Äôs on your head, finding the
hole for the screw can be quite tricky, although after a few runs you
kinda get a sense for it. üòè</p>
<h2 id="pros-and-cons-table" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/best-gopro-position-skiing.html#pros-and-cons-table"><span>Pros and cons table</span></a></h2>
<p>To summarize, I‚Äôll compare those 3 options with a number of criteria:</p>
<ul>
<li><strong>POV:</strong> how realistic is the point of view footage.</li>
<li><strong>Compatibility:</strong> can you use it with most gear or is it tricky?</li>
<li><strong>Comfort:</strong> how comfortable, or tiring is it.</li>
<li><strong>Maneuverability:</strong> is it easy to take off and on?</li>
<li><strong>Look around:</strong> do the camera follow you when you look around?</li>
<li><strong>Stability:</strong> how stable is the footage.</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>Helmet top</th>
<th>Helmet side</th>
<th>Chest</th>
</tr>
</thead>
<tbody>
<tr>
<td>POV</td>
<td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ</td>
<td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ</td>
<td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ</td>
</tr>
<tr>
<td>Compatibility</td>
<td>‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ</td>
<td>‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ</td>
<td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ</td>
</tr>
<tr>
<td>Comfort</td>
<td>‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ</td>
<td>‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ</td>
<td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ</td>
</tr>
<tr>
<td>Maneuverability</td>
<td>‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ</td>
<td>‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ</td>
<td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ</td>
</tr>
<tr>
<td>Look around</td>
<td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ</td>
<td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ</td>
<td>‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ</td>
</tr>
<tr>
<td>Stability</td>
<td>‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ</td>
<td>‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ</td>
<td>‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ</td>
</tr>
</tbody>
</table>
<p>The helmet top POV is the most conventional, but <strong>only when the mount
it put at the frontmost part of the helmet</strong>. If it‚Äôs put higher, it
quickly feels too high and loses some of its immersiveness, and you risk
seeing a bit of the helmet at the bottom of the frame.</p>
<p>The side mount is a more typical kind of POV that might not be to the
taste of everyone, but I personally really like it. Same goes for the
chest mount.</p>
<p>The comfort of a top mount might be better with your particular
helmet/goggles combination but for me it was a no-no. Also if you want
to put the mount at the frontmost part, which is where it looks the
best, you lose the ability to put your goggles up on your helmet, and
I find that quite annoying.</p>
<p>Still better than the side mount where it‚Äôs basically incompatible with
having a goggles strap, but might work for you if your helmet has a
built-in visor.</p>
<p>The chest mount won‚Äôt follow your face when you look around, so you
might not be able to capture a sudden event around you where you‚Äôre not
directly facing. But we‚Äôve seen this also gives a much more stable image
and lets you freely move your head around (e.g. for safety) without
making your viewer nauseous.</p>
<p>When I‚Äôm not recording, I was wondering how annoying it would be to wear
the chest strap, and if I needed to take it off and on all the time. It
turns out the chest strap is really not a big deal, I can wear it all
day long without even noticing it‚Äôs there.</p>
<h2 id="what-about-the-field-of-view" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/best-gopro-position-skiing.html#what-about-the-field-of-view"><span>What about the field of view?</span></a></h2>
<p>In all cases, SuperView. While in my <a href="https://www.codejam.info/2020/06/my-settings-for-gopro-hero-2018-and-hero5-black.html">my GoPro settings post</a>
I said I prefer wide to SuperView, skiing is the exception.</p>
<p>When shooting POV skiing in anything else than SuperView, you‚Äôre mostly
just gonna see the snow and little to nothing of the landscape in front
of and around you.</p>
<p>SuperView all the way, trust me.</p>
<h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/best-gopro-position-skiing.html#conclusion"><span>Conclusion</span></a></h2>
<p>At the end of the day, the <a href="https://amzn.to/3sXrOcR">chest mount</a> won
for me: it‚Äôs by far <strong>the most comfortable and practical solution</strong>, so
that the fact I‚Äôm recording a video doesn‚Äôt impact my skiing experience
whatsoever.</p>
<p>This is a huge deal for me. If recording a video takes effort and
negatively affects my skiing, I‚Äôm less likely to do it, and at the end
of the day that might make me miss some runs that would have been really
cool to have on video. With a chest mount, especially now my GoPro can
<a href="https://www.codejam.info/2022/05/gopro-canadian-winter.html">handle the cold</a>, I can record liberally
while still having a great time. After all, I‚Äôm here <strong>mostly to ski,
not just to record a video</strong>.</p>
<p>On top of that, I like the chest mount POV quite a lot, despite being a
bit unconventional. I find it very immersive, and we get a great view of
the skis, the slope and the landscape around, all at the same time.</p>
<p>As a bonus, it seems my chest is better at absorbing shocks and
stabilizing footage than my head is. And the footage is smoother overall
because my chest is not moving as much as my head while skiing.</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Start a conversation on <a href="https://twitter.com/valeriangalliat">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Using a GoPro in the Canadian winter ‚ùÑÔ∏è</title>
    <link href="https://www.codejam.info/2022/05/gopro-canadian-winter.html" />
    <id>https://www.codejam.info/2022/05/gopro-canadian-winter.html</id>
    <updated>2022-05-25T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>If you ever used a GoPro in a very cold weather, I‚Äôm talking -20 or even -30 ¬∞C,
you probably noticed that its battery dies extremely fast. It‚Äôs
sometimes a matter of <em>minutes</em> before it shuts off and refuses to start
again until it‚Äôs warmed up again.</p>
<p><a href="https://www.newschoolers.com/forum/thread/919646/GoPro-Hero8-Can-t-Handle-the-Cold">The</a>
<a href="https://www.reddit.com/r/gopro/comments/kd48w1/gopro_hero_9_turns_off_at_cold_temperatures/">internet</a>
<a href="https://www.quora.com/I-wanted-to-use-my-GoPro-Hero-4-today-while-snowboarding-but-the-battery-died-prematurely-due-to-the-cold-What-is-a-way-of-getting-around-this-issue">is</a>
<a href="https://www.hardcoresledder.com/threads/gopro-camera-stops-in-cold-weather.620282/page-2">full</a>
<a href="https://www.codejam.info/img/2022/05/gopro-cold-weather.png">of</a>
<a href="https://youtu.be/WK6oi7x_sNU">people</a>
<a href="https://youtu.be/eeI7bTvlXyg">having</a>
<a href="https://youtu.be/noGoux3Yya4">issues</a>
<a href="https://youtu.be/9SnPMeXVK3E">with</a>
<a href="https://youtu.be/mU-FOWcvZNg">their</a>
<a href="https://youtu.be/FlqLFW9DZVk">GoPro</a>
(any version especially after HERO4) dying ridiculously fast after being used
in cold weather, e.g. with winter sports.</p>
<blockquote>
<p>In any conditions below 20 ¬∞F / -10 ¬∞C my GoPro HERO8 renders itself
utterly useless with the battery dying after about 10 minutes of
filming.
[<a href="https://www.newschoolers.com/forum/thread/919646/GoPro-Hero8-Can-t-Handle-the-Cold">Source</a>]</p>
<p>I am skiing right now with a GoPro max. I can‚Äôt even take it outside before it dies. 6-7 degrees below Celsius.
[<a href="https://www.reddit.com/r/gopro/comments/kd48w1/gopro_hero_9_turns_off_at_cold_temperatures/">Source</a>]</p>
<p>Found the same problem on my HERO8 Black. Tested in -27 here in Norway and it died immediately after 2-3 clips.
[<a href="https://youtu.be/FlqLFW9DZVk">Source</a>]</p>
<p>Battery life has been a real pain for me as well using it during the
winter months. I keep my camera and batteries in my pants pockets
until I need them but even doing that might yield me five minutes of
recording once it‚Äôs exposed to sub-zero temps.
[<a href="https://youtu.be/FlqLFW9DZVk">Source</a>]</p>
</blockquote>
<p>And it seems like it‚Äôs <a href="https://forum.dji.com/forum.php?mod=viewthread&amp;tid=252188">not just a problem with GoPro</a>.</p>
<blockquote>
<p>When the temperature is below -10 ‚ÑÉ, DJI Action 2 cannot be turned on.</p>
</blockquote>
<p>There‚Äôs a number of tips, lots of them that I‚Äôm not really read for.</p>
<blockquote>
<p>When you finish your line, stop and take the GoPro off and put it in a
pocket or backpack, take the battery out and put it back in warm
pocket.
[<a href="https://www.newschoolers.com/forum/thread/919646/GoPro-Hero8-Can-t-Handle-the-Cold">Source</a>]</p>
<p>Definitely worth buying an extra set of batteries. I‚Äôve gone through
4+ on a good pow day.
[<a href="https://www.newschoolers.com/forum/thread/919646/GoPro-Hero8-Can-t-Handle-the-Cold">Source</a>]</p>
<p>If you want to capture winter sports such as skiing, snowboarding,
sled dog racing etc., don‚Äôt waste your hard earned money on a Go Pro.
[<a href="https://www.newschoolers.com/forum/thread/919646/GoPro-Hero8-Can-t-Handle-the-Cold">Source</a>]</p>
</blockquote>
<p>You also see people putting it in a <a href="https://youtu.be/9SnPMeXVK3E">foam cover</a>
or others <a href="https://youtu.be/WK6oi7x_sNU">storing it in a bag</a> with <a href="https://youtu.be/eeI7bTvlXyg">hand
or feet warmers</a> when not in use.</p>
<h2 id="the-problem-with-the-default-case" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/gopro-canadian-winter.html#the-problem-with-the-default-case"><span>The problem with the default case</span></a></h2>
<p>I was actually surprised the first time I mounted the GoPro on my
helmet and I saw it die that fast. In the past I‚Äôve used that same GoPro
hand-held, an I remember being able to shoot quite a lot, and still had
some battery left at the end of a ski day.</p>
<p>So what could be the culprit? Sure when it‚Äôs mounted on my helmet I tend
to leave it outside a bit more, whereas before I would store it in my
pocket when it‚Äôs not recording, but I‚Äôve made a habit of taking it off
my helmet and putting it in my pocket during the lifts too, and still
had the same issues.</p>
<p>I‚Äôve tried different pockets, jacket pocket, pants pocket, internal
pocket, but it wouldn‚Äôt make much difference. It was always dead after a
few hours of being outside, regardless if I was recording a lot or
keeping it in my pocket most of the time.</p>
<p>One day, I‚Äôve even kept the GoPro in my pants pocket (turned out to be
the warmest) for an hour or two before first using it, and it was
<strong>already dead</strong> when I tried to record! WTF?</p>
<p>So I decided to <strong>try something</strong> and just use it hand-held like I used
to in the previous years, to see if my battery degraded significantly
over time or something. <strong>Turned out it performed great</strong> and I could
shoot plenty of hand-held shots the whole day without it dying at any
point!</p>
<p>Then I realized: the <em>only</em> difference between that day where it died in
my pocket before I even use it, and that time where I could record
hand-held all day, was <strong>the plastic case</strong>.</p>
<p>When I plan to use it hand-held only, I don‚Äôt put it in the black
plastic case that allows me to mount it.</p>
<ul>
<li>GoPro without case stored in pocket all day: <strong>full battery</strong>.</li>
<li>GoPro with case stored in pocket all day: <strong>battery dead after a
couple hours</strong>.</li>
</ul>
<p>Luckily if you have a newer GoPro, you don‚Äôt need a case to mount it
anymore, so this shouldn‚Äôt be as much of a problem. But if using one of
the GoPro that can only be mounted with a case, it‚Äôs a deal breaker!</p>
<h2 id="introducing-the-super-suit" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/gopro-canadian-winter.html#introducing-the-super-suit"><span>Introducing the Super Suit</span></a></h2>
<p>The <a href="https://amzn.to/3wP6ZkX">Super Suit</a>, alias ‚Äúprotection + dive
housing‚Äù and now renamed to <a href="https://amzn.to/3LMDaaa">‚Äúprotective housing + waterproof case‚Äù</a>
for the newer models, is a transparent waterproof case for your GoPro.</p>
<figure class="center">
  <img alt="GoPro Super Suit" src="https://www.codejam.info/img/2022/05/gopro-super-suit.jpg">
</figure>
<p>It‚Äôs designed to be used for diving under water, but as
<a href="https://www.hardcoresledder.com/threads/gopro-camera-stops-in-cold-weather.620282/post-20359482">some users</a>
<a href="https://youtu.be/pXfNA-xqETA">pointed out</a>, it does a great job at
protecting from the cold too. It seems this is a very little known trick
for this problem!</p>
<p>I <a href="https://amzn.to/3wP6ZkX">ordered one</a> and was shocked of the
difference it made. <strong>I was no longer running out of battery during the
day.</strong></p>
<p>I could record as much as I wanted at any time of the day and the GoPro
was always there and had plenty of battery life!</p>
<p>I don‚Äôt record necessary <em>a lot</em> while I ski: between 30 minutes to 2
hours of content during a 6 hours ski day. Still, <strong>before the Super
Suit, the GoPro would die in the first 2 hours of skiing</strong>, regardless
of whether it was recording or stored in my pocket the whole time.</p>
<p>After the Super Suit, I can not only record <strong>over 2 hours of content</strong>,
but I can do so <strong>over the course of the whole day</strong>, as long as I keep
it in my pocket when it‚Äôs not recording!</p>
<h2 id="impact-on-audio" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/gopro-canadian-winter.html#impact-on-audio"><span>Impact on audio</span></a></h2>
<p>One of the known downsides of the waterproof housing is that it muffles
the audio. It <em>does</em> sound like it‚Äôs inside a hermetic case.</p>
<p>This is a problem especially for voice: my own voice is somewhat audible
although not super crisp, but we can barely hear people talking around
me. This leads to some scenes where it sounds like I‚Äôm talking alone. üòÇ</p>
<p>But to be honest my HERO5 built-in audio has never been great, so if I
want to record somewhat usable vocals, I need to bring a real microphone
anyways. It seems that a lavalier microphone placed <em>inside</em> the collar
of a ski jacket is fantastic at recording your voice while skiing,
although I‚Äôve never tried myself.</p>
<p>For the ambient sound though, I‚Äôve found the muffled sound of the Super
Suit <strong>perfect to cancel the wind while skiing</strong>, so that we just hear
the skis gliding on the snow. This is in fact <strong>much better</strong> than what
we would otherwise get with the default case or no case (mostly wind,
skis not so much), and is actually usable as is!</p>
<p>I‚Äôve also seen in <a href="https://youtu.be/pXfNA-xqETA">this video</a> a setup
where they drilled tiny holes in the Super Suit around the different
GoPro microphones locations, and covered them with a wind muff. It seems
to give pretty solid results, but I don‚Äôt have the tools to do that
myself, and I guess I like that I can actually use my Super Suit for
diving if I want to. üòÑ</p>
<h2 id="in-short" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/gopro-canadian-winter.html#in-short"><span>In short</span></a></h2>
<p>GoPro dies in cold weather?</p>
<ul>
<li>Get a Super Suit, <a href="https://amzn.to/3wP6ZkX">Super Suit</a>,
alias <a href="https://amzn.to/3LMDaaa">‚Äúprotective housing + waterproof case‚Äù</a>
for newer models.</li>
<li>Keep the GoPro in your warmest pocket while not recording, don‚Äôt let
it turned off mounted on your helmet all day!</li>
<li>Record voices with a lavalier microphone if you need quality dialogue.</li>
</ul>
<p>I hope those tips help you to record more cool content while you‚Äôre
outside in the cold winter! If you found this post useful, you might also
like my article about <a href="https://www.codejam.info/2022/05/best-gopro-position-skiing.html">the best GoPro mount position for skiing</a>,
as well as <a href="https://www.codejam.info/2020/06/my-settings-for-gopro-hero-2018-and-hero5-black.html">my GoPro settings</a>.</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Start a conversation on <a href="https://twitter.com/valeriangalliat">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Migrating from X11 to Wayland and from i3 to Sway</title>
    <link href="https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html" />
    <id>https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html</id>
    <updated>2022-05-15T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Finally. After so long. I switched to Wayland. üéâ</p>
<p>I remember back when I started using Linux, more than 10 years ago now,
I was already reading about Wayland, and seeing early adopters on forums
using it and loving it despite running into all kinds of issues‚Ä¶ this
wasn‚Äôt for me. X11, while old and outdated, was well supported for
everything I wanted to do, and that was awesome.</p>
<p>But the other day, I was bored or something, and I asked myself: is
Wayland mainstream enough for me to use it yet?</p>
<p>The answer was‚Ä¶ nearly yes. Yes enough for me to switch. And that‚Äôs a
fucking good news.</p>
<p>In this post I‚Äôll share with you what was needed to <strong>get a usable Wayland
server running with Sway</strong>, all the Wayland alternatives to the X11
programs I was previously using, and finally how I completely purged
X11 from my system.</p>
<p>I‚Äôm a Arch Linux user, so the commands will be adapted to that system.</p>
<h2 id="installing-wayland-and-sway" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html#installing-wayland-and-sway"><span>Installing Wayland and Sway</span></a></h2>
<p>Being a long time <a href="https://i3wm.org/">i3</a> user,
<a href="https://swaywm.org/">Sway</a> was the obvious choice as a Wayland
compositor. The fact it‚Äôs compatible with my existing i3 config should
ease the transition quite a lot.</p>
<pre><code class="hljs language-sh">pacman -S wayland sway
</code></pre>
<p>Then from a TTY I could just run <code>sway</code>, and end up in an environment
pretty close to my habitual i3! Good start.</p>
<h2 id="figuring-all-the-wayland-alternatives" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html#figuring-all-the-wayland-alternatives"><span>Figuring all the Wayland alternatives</span></a></h2>
<p>There‚Äôs a number of X11 programs that I was using, that just don‚Äôt work
on Wayland. The good thing is that the Wayland ecosystem is mature
enough nowadays that there was a solid alternative for all of them!</p>
<ul>
<li><a href="https://tools.suckless.org/dmenu/">dmenu</a>, the great simple dynamic menu
is now <a href="https://github.com/Cloudef/bemenu">bemenu</a>.</li>
<li><a href="https://feh.finalrewind.org/">feh</a>, the fast and light image
viewer, is now <a href="https://sr.ht/~exec64/imv/">imv</a>.</li>
<li><a href="https://github.com/naelstrof/maim">maim</a> (the improved
<a href="https://github.com/resurrecting-open-source-projects/scrot">scrot</a>)
to take screenshots is replaced by <a href="https://sr.ht/~emersion/grim/">grim</a>,
with <a href="https://github.com/emersion/slurp">slurp</a> to select a region.</li>
<li><a href="https://github.com/astrand/xclip">xclip</a> and <a href="https://vergenet.net/~conrad/software/xsel/">XSel</a>
that allow to manipulate the selection and clipboard from the terminal
are replaced by <a href="https://github.com/bugaevc/wl-clipboard">wl-clipboard</a>
(providing <code>wl-copy</code> and <code>wl-paste</code>).</li>
<li><code>xbacklight</code> that helps controlling the screen backlight is now
<a href="https://github.com/haikarainen/light">Light</a>.</li>
<li><a href="https://www.semicomplete.com/projects/xdotool/">xdotool</a> that I
<a href="https://github.com/valeriangalliat/dmenumoji/blob/997e48c69315131b32f9e3368b88151f811d14eb/dmenumoji#L24">use to type an emoji</a>
in my <a href="https://github.com/valeriangalliat/dmenumoji">dmenumoji</a> emoji
picker is now <a href="https://github.com/atx/wtype">wtype</a> (and I made a
<a href="https://github.com/valeriangalliat/dotfiles/blob/14bcdb5d9e7c9d14f15cf3af33c0c862e18bdfb2/bin/bemenumoji"><code>bemenumoji</code></a>
script instead).</li>
<li><a href="http://jonls.dk/redshift/">Redshift</a> that gives an orange tint to the
screen in the evening, is now <a href="https://gitlab.com/chinstrap/gammastep">Gammastep</a>.</li>
</ul>
<p>There‚Äôs also a number of programs that are no longer needed:</p>
<ul>
<li><a href="https://bitbucket.org/raymonad/xss-lock">xss-lock</a> that I used to
lock the screen on suspend and hibernate is superseded by
<a href="https://github.com/swaywm/swayidle">swayidle</a>.</li>
<li><a href="https://gitlab.com/jD91mZM2/xidlehook">xidlehook</a> (the replacement
for <a href="https://linux.die.net/man/1/xautolock">xautolock</a>) allowing to
execute commands after a certain idle period (like dim screen, lock,
suspend), is superseded by <a href="https://github.com/swaywm/swayidle">swayidle</a>
too.</li>
<li><code>xset</code> that I used to set to lower the keyboard repeat delay is
replaced by the <code>repeat_delay</code> Sway option.</li>
<li><a href="https://github.com/yshui/picom">picom</a>, the compositor I used with
X11 is no longer needed because Sway itself is a compositor.</li>
</ul>
<p>So in the end, this leaves us with the following commands:</p>
<pre><code class="hljs language-sh">pacman -S bemenu-wayland imv grim slurp wl-clipboard light wtype gammastep
pacman -Rns dmenu feh maim xclip xsel xorg-xbacklight xdotool redshift xss-lock xidlehook xorg-xset picom
</code></pre>
<p>Because <a href="https://codeberg.org/dnkl/foot">foot</a> is the default terminal
emulator of Sway, I <a href="https://www.codejam.info/2022/04/xfce4-terminal-vs-foot.html">decided to try it</a>
instead of my usual <a href="https://docs.xfce.org/apps/terminal/start">xfce4-terminal</a>.
That wasn‚Äôt a complete success for me and I rolled back to
xfce4-terminal since it works just fine on Wayland anyways!</p>
<p>Finally, I had a few <code>.xmodmaprc</code> modifications that I use to
<a href="https://github.com/valeriangalliat/dotfiles/blob/1d2098a7da513dab195554997efaac22a0d77a02/x11/xmodmaprc">invert <kbd>Alt</kbd> and <kbd>Ctrl</kbd></a>
and also <a href="https://www.codejam.info/2019/06/software-fn-lock.html">emulate <kbd>Fn Lock</kbd></a>
because it‚Äôs not supported on my laptop.</p>
<p>xmodmap is a X11-only thing, and I had to <a href="https://www.codejam.info/2022/04/xmodmaprc-wayland.html">configure XKB directly</a>
to reproduce this behavior. XKB stands for ‚ÄúX keyboard extension‚Äù but it
is also <a href="https://wayland-book.com/seat/xkb.html">used by Wayland</a>.</p>
<h2 id="full-diff" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html#full-diff"><span>Full diff</span></a></h2>
<p>If you want to see the details, here‚Äôs
<a href="https://github.com/valeriangalliat/dotfiles/commit/537f9e14f332b6591a7d932aee056d4d412ec873#diff-d46a2e36b87ce6bb331477a420580121b2fe0c856f81fd5176053ffc4e0828af">the link to the full diff in my dotfiles</a>.</p>
<p>I anchored it to the conversion from <code>~/.config/i3/config</code> to
<code>~/.config/sway/config</code> but feel free to move around and see the other
changes I did.</p>
<p>I took this as an opportunity to change a few unrelated things in there
so not all the modifications were strictly necessary.</p>
<h2 id="cleaning-up" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html#cleaning-up"><span>Cleaning up</span></a></h2>
<p>Now we have a working Wayland and Sway installation, we can remove X11
altogether from the system! Or can we?</p>
<pre><code class="hljs language-sh">pacman -Rns xorg-server i3
</code></pre>
<p>Turns out this didn‚Äôt work for me. VLC, <a href="https://mpv.io/">mpv</a>, Chromium
and <a href="https://calibre-ebook.com/">calibre</a> all required some X11
dependency that would be removed by this command. Bummer.</p>
<p>So what I did instead:</p>
<pre><code class="hljs language-sh">pacman -Rns xorg-server i3 vlc mpv chromium calibre
pacman -S vlc mpv chromium calibre
</code></pre>
<h2 id="quirks" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html#quirks"><span>Quirks</span></a></h2>
<h3 id="qt-and-wayland" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html#qt-and-wayland"><span>Qt and Wayland</span></a></h3>
<p>VLC and calibre both use Qt, and as <a href="https://wiki.archlinux.org/title/wayland#Qt">documented on the ArchWiki</a>,
we need to install <code>qt5-wayland</code> for Qt to work.</p>
<h3 id="special-flags-for-chromium" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html#special-flags-for-chromium"><span>Special flags for Chromium</span></a></h3>
<p>Programs built on Chromium (including Chromium itself obviously) support
Wayland <em>nearly</em> out of the box, but they require some kind of flag to
enable the support. Not really sure why this is a thing, but basically I
need to start Chromium and Visual Studio Code like this:</p>
<pre><code class="hljs language-sh">chromium --ozone-platform-hint=auto
code --enable-features=UseOzonePlatform --ozone-platform=wayland
</code></pre>
<p>I use those programs once in a blue moon anyways, so I don‚Äôt really
care.</p>
<h3 id="idle-inhibitor" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html#idle-inhibitor"><span>Idle inhibitor</span></a></h3>
<p>I used to use <code>xidlehook --not-when-audio</code> to prevent dimming the
screen, disconnecting the screen, or locking the computer after an idle
period if there‚Äôs audio playing.</p>
<p>This is great for example when watching a movie‚Ä¶ you don‚Äôt necessarily
actively use the computer but you don‚Äôt want it to lock and suspend or
hibernate while it‚Äôs playing either!</p>
<p>Some programs like mpv support inhibiting idle while playing, which
is great, but others like VLC and Firefox don‚Äôt.</p>
<p>In general, the ‚Äúnot when audio‚Äù trick was a pretty good fallback that
didn‚Äôt require any custom implementation in existing programs.</p>
<p>Luckily, there‚Äôs <a href="https://github.com/ErikReider/SwayAudioIdleInhibit">SwayAudioIdleInhibit</a>
(<a href="https://aur.archlinux.org/packages/sway-audio-idle-inhibit-git">on the AUR</a>)
that does exactly that. Fantastic.</p>
<p>The only quirk I noticed with it is that in Firefox, some very specific
sites like <a href="https://artlist.io/">Artlist</a> (the only one I identified so
far) manage to register an active audio channel at all times even if
they‚Äôre not playing anything, and as long as the tab is open, idle will
be inhibited. This is not good as I tend to keep tabs around for days if
not weeks!</p>
<p>To be able to notice when this happens more easily, I
<a href="https://github.com/valeriangalliat/dotfiles/commit/2fd9359a6a0e76891b6b10fe1ef97f7aec35f926">modified my i3blocks volume block</a>
to display a different icon whether or not there‚Äôs any PulseAudio sink
in state <code>RUNNING</code>.</p>
<h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/migrating-x11-wayland-i3-sway.html#conclusion"><span>Conclusion</span></a></h2>
<p>Migrating to Wayland was a pretty smooth transition at the end of the
day, and I‚Äôm glad I finally did it! Everything works great, it seems
like Wayland programs are usually more recent and have better UX than
their X11 equivalent that I was previously using.</p>
<p>For example I love the <em>slurp</em> screen selection, and I don‚Äôt have to
<a href="https://www.codejam.info/2021/08/dmenu-libxft-bgra-emoji-support.html">patch dmenu</a> anymore
in order to support emojis, since they natively work with bemenu, and
basically everything else?</p>
<p>Also I realized that Wayland allowed me to zoom in on any part of the
screen with my trackpad out of the box, and that‚Äôs pretty useful. One of
the features I was kinda missing from MacBooks but never spent the time
to figure if I could do it or not with X11.</p>
<p>If you‚Äôve been thinking about migrating to Wayland, it‚Äôs probably a good
time to do so!</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Join the discussion on <a href="https://twitter.com/valeriangalliat/status/1525897795844153344">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>How to make a GitHub Action that exposes a SSH server</title>
    <link href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html" />
    <id>https://www.codejam.info/2022/05/github-action-expose-ssh-server.html</id>
    <updated>2022-05-14T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>In the <a href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html">first post</a>, I
explained how to use <a href="https://github.com/valeriangalliat/action-sshd-cloudflared">action-sshd-cloudflared</a>,
a GitHub Action that I wrote to easily SSH to a GitHub workflow
container and debug it efficiently. I gave a precise explanation of
<a href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#details-of-the-client-connect-commands">what the client commands do</a>,
and I <a href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#what-about-action-upterm-and-action-tmate">compared it to similar alternatives</a>.</p>
<p>In this post, we‚Äôll go through the details of the server (the code that
runs inside the GitHub workflow). We‚Äôll see how to make a simple GitHub
Action that runs a shell script (or anything <em>executable</em>), a couple
useful environment variables, and most importantly, what‚Äôs the recipe to
run a SSH server there and expose it over the internet despite the
container not being publicly addressable.</p>
<h2 id="making-the-simplest-github-action-possible" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#making-the-simplest-github-action-possible"><span>Making the simplest GitHub Action possible</span></a></h2>
<p>All we need to turn a simple GitHub repository in a GitHub Action is to
add a valid <code>action.yml</code> at the top level.</p>
<p>GitHub can run
<a href="https://docs.github.com/en/actions/creating-actions/creating-a-docker-container-action">Docker actions</a>,
<a href="https://docs.github.com/en/actions/creating-actions/creating-a-javascript-action">JavaScript actions</a>,
but the one we care about is the <a href="https://docs.github.com/en/actions/creating-actions/creating-a-composite-action">composite action</a>.
A composite action allows us to run simple <em>commands</em> in a <em>shell</em> and
that‚Äôs exactly what we need. üëç</p>
<pre><code class="hljs language-yaml"><span class="hljs-attr">name:</span> <span class="hljs-string">Debug</span> <span class="hljs-string">via</span> <span class="hljs-string">SSH</span>
<span class="hljs-attr">description:</span> <span class="hljs-string">Setup</span> <span class="hljs-string">a</span> <span class="hljs-string">SSH</span> <span class="hljs-string">server</span> <span class="hljs-string">with</span> <span class="hljs-string">a</span> <span class="hljs-string">tunnel</span> <span class="hljs-string">to</span> <span class="hljs-string">access</span> <span class="hljs-string">it</span> <span class="hljs-string">to</span> <span class="hljs-string">debug</span> <span class="hljs-string">your</span> <span class="hljs-string">action</span> <span class="hljs-string">via</span> <span class="hljs-string">SSH.</span>
<span class="hljs-attr">runs:</span>
  <span class="hljs-attr">using:</span> <span class="hljs-string">composite</span>
  <span class="hljs-attr">steps:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">run:</span> <span class="hljs-string">$GITHUB_ACTION_PATH/setup-ssh</span>
      <span class="hljs-attr">shell:</span> <span class="hljs-string">bash</span>
</code></pre>
<p>Unlike in a normal workflow YAML, the <code>run</code> command must also include an
explicit shell. We can use any of the <a href="https://docs.github.com/en/actions/learn-github-actions/environment-variables">GitHub Actions environment variables</a>
directly in there, which is convenient because we have
<code>GITHUB_ACTION_PATH</code>, the path to our action repository (by default the
working directory is the one containing the user‚Äôs code, not our action
code).</p>
<p>From there, the <a href="https://github.com/valeriangalliat/action-sshd-cloudflared/blob/master/setup-ssh"><code>setup-ssh</code> script</a>
can be broken down in 9 simple steps:</p>
<ol>
<li><a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#download-cloudflared">Download the latest <code>cloudflared</code> binary</a>.</li>
<li><a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#fetch-the-actor-keys">Fetch the public SSH keys</a> of the GitHub user
who triggered the workflow to a <code>authorized_keys</code> file.</li>
<li><a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#set-a-password">If there was no SSH key, set a password</a> for the
<code>runner</code> user so that there‚Äôs alternative way to connect.</li>
<li><a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#generate-a-server-key">Generate a server key</a>.</li>
<li><a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#create-the-sshd-config">Create the <code>sshd</code> config</a>.</li>
<li><a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#start-sshd">Start <code>sshd</code></a>.</li>
<li><a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#start-a-tmux-session">Start a tmux session</a>.</li>
<li><a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#start-cloudflared">Start <code>cloudflared</code></a> to expose the <code>sshd</code> port on the internet.</li>
<li><a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#output-the-client-instructions">Output the client instructions</a>.</li>
<li><a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#watch-for-session-end">Wait for the tmux session to end and stop everything</a>.</li>
</ol>
<h2 id="download-cloudflared" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#download-cloudflared"><span>Download <code>cloudflared</code></span></a></h2>
<p>We start simple and easy.</p>
<pre><code class="hljs language-sh">curl --location --silent --output cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64
<span class="hljs-built_in">chmod</span> +x cloudflared
</code></pre>
<h2 id="fetch-the-actor-keys" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#fetch-the-actor-keys"><span>Fetch the actor keys</span></a></h2>
<p>In GitHub Actions, the user who trigger the workflow is called an
‚Äúactor‚Äù. Their username is set in the <code>GITHUB_ACTOR</code> environment
variable.</p>
<p>As you may know, <a href="https://github.com/settings/keys">you configured</a> a
number of SSH keys on GitHub to be able to push to repositories over
SSH. Those keys are public knowledge, and we can fetch them via the
public GitHub API, which is convenient here to automatically give the
actor SSH access to that server.</p>
<pre><code class="hljs language-sh">curl -s <span class="hljs-string">&quot;https://api.github.com/users/<span class="hljs-variable">$GITHUB_ACTOR</span>/keys&quot;</span> | jq -r <span class="hljs-string">&#x27;.[].key&#x27;</span> &gt; authorized_keys
</code></pre>
<p>The GitHub API response is in JSON, but we use a simple <a href="https://stedolan.github.io/jq/">jq</a>
script to extract the raw key, one per line, to put it in a valid
<code>authorized_keys</code> file.</p>
<h2 id="set-a-password" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#set-a-password"><span>Set a password</span></a></h2>
<p>If there was no SSH keys for that user, we set a password as a fallback,
so they still have a means to connect.</p>
<p>To test whether or not there was any SSH key, we use:</p>
<pre><code class="hljs language-sh">grep -q . authorized_keys
</code></pre>
<p><code>-q</code> makes <code>grep</code> quiet (we don‚Äôt need to display the output), <code>.</code> is
the regular expression to match (any character), and <code>authorized_keys</code>
is the file we use as input.</p>
<p>If there‚Äôs any character in that file, <code>grep</code> will exit with 0
(success). Otherwise with a nonzero code, which means nothing was
matched.</p>
<p>We can conveniently use it in a <code>if</code> condition:</p>
<pre><code class="hljs language-sh"><span class="hljs-keyword">if</span> grep -q . authorized_keys; <span class="hljs-keyword">then</span>
    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Configured SSH key(s) for user: <span class="hljs-variable">$GITHUB_ACTOR</span>&quot;</span>
<span class="hljs-keyword">else</span>
    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;No SSH key found for user: <span class="hljs-variable">$GITHUB_ACTOR</span>&quot;</span>
    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Setting SSH password...&quot;</span>
<span class="hljs-keyword">fi</span>
</code></pre>
<p>It‚Äôs in that <code>else</code> branch that we generate and set the password. To
generate it, we fetch 16 characters from <code>/dev/urandom</code>:</p>
<pre><code class="hljs language-sh">password=$(<span class="hljs-built_in">base64</span> &lt; /dev/urandom | <span class="hljs-built_in">tr</span> -<span class="hljs-built_in">cd</span> <span class="hljs-string">&#x27;[:alnum:]&#x27;</span> | <span class="hljs-built_in">head</span> -c16)
</code></pre>
<ul>
<li><code>base64 &lt; /dev/urandom</code> encodes as Base64 the stream of random bytes
from <code>/dev/urandom</code>. The stream is infinite but the pipleine is
‚Äúlazy‚Äù.</li>
<li><code>tr -cd '[:alnum:]'</code> keeps only alphanumeric characters.</li>
<li><code>head -c16</code> keeps only the first 16 characters (or should I say,
bytes, to be accurate) and terminates the stream as soon as it has
them.</li>
</ul>
<p>This gives us a password that we can set for the current user.</p>
<pre><code class="hljs language-sh">(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$password</span>&quot;</span>; <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$password</span>&quot;</span>) | sudo passwd <span class="hljs-string">&quot;<span class="hljs-variable">$USER</span>&quot;</span>
</code></pre>
<p>We can‚Äôt use the <code>passwd</code> command directly because it first prompts us
for our own current password (which we don‚Äôt know), but we have <code>root</code>
access in this VM through <code>sudo</code>, and <code>root</code> doesn‚Äôt need confirmation
to change anyone‚Äôs password.</p>
<p>We echo the password twice because <code>passwd</code> typically asks to input the
password first, then a second time for confirmation.</p>
<h2 id="generate-a-server-key" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#generate-a-server-key"><span>Generate a server key</span></a></h2>
<p><code>ssh-keygen</code> is a cool utility to generate SSH keys. It defaults to a
RSA key which is fine with me.</p>
<ul>
<li><code>-q</code> makes it quiet (we don‚Äôt need the logs).</li>
<li><code>-f</code> indicates the output file to write the key to (the public key
will be in a file with a <code>.pub</code> suffix).</li>
<li><code>-N ''</code> is to set an empty passphrase (otherwise <code>ssh-keygen</code> will
prompt to set a passphrase).</li>
</ul>
<pre><code class="hljs language-sh">ssh-keygen -q -f ssh_host_rsa_key -N <span class="hljs-string">&#x27;&#x27;</span>
</code></pre>
<h2 id="create-the-sshd-config" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#create-the-sshd-config"><span>Create the <code>sshd</code> config</span></a></h2>
<p>We copy it from a template file, where we just replace the <code>$PWD</code> and
<code>$USER</code> symbols by the corresponding environment variable.</p>
<pre><code class="hljs language-sh">sed <span class="hljs-string">&quot;s,\$PWD,<span class="hljs-variable">$PWD</span>,;s,\$USER,<span class="hljs-variable">$USER</span>,&quot;</span> sshd_config.template &gt; sshd_config
</code></pre>
<p>This is a good time to review the template. It‚Äôs heavily based on my
<a href="https://www.codejam.info/2021/11/standalone-userland-ssh-server.html">standalone userland SSH server</a>
config I <a href="https://github.com/valeriangalliat/sshd-on-the-go">published</a>
last year!</p>
<pre><code class="hljs language-apache"><span class="hljs-attribute">Port</span> <span class="hljs-number">2222</span>
<span class="hljs-attribute">HostKey</span> $PWD/ssh_host_rsa_key
<span class="hljs-attribute">PidFile</span> $PWD/sshd.pid
</code></pre>
<p>First we set the port to 2222, and we define the host key and process ID
file. We could have written <code>PidFile none</code> to prevent the default of
<code>/run/sshd.pid</code>, because we don‚Äôt actually use it, but it doesn‚Äôt hurt.</p>
<pre><code class="hljs language-apache"><span class="hljs-attribute">UsePAM</span> yes
</code></pre>
<p>We enable PAM (pluggable authentication module). Not going in details
with this, but keep in mind it‚Äôs required for this to work at least on
Debian-based systems.</p>
<pre><code class="hljs language-apache"><span class="hljs-attribute">KbdInteractiveAuthentication</span> yes
<span class="hljs-attribute">ChallengeResponseAuthentication</span> yes
<span class="hljs-attribute">PasswordAuthentication</span> yes
</code></pre>
<p>This enables interactive password authentication. They‚Äôre actually
enabled by default so we could leave them out.</p>
<pre><code class="hljs language-apache"><span class="hljs-attribute">AllowUsers</span> $USER
<span class="hljs-attribute">AuthorizedKeysFile</span> $PWD/authorized_keys
</code></pre>
<p>We only allow the Unix user who the workflow is running as, and we allow
the SSH keys we fetched earlier in <code>authorized_keys</code>. Remember that we
replace those <code>$USER</code> and <code>$PWD</code> symbols with a <code>sed</code> command before
starting the server, you can‚Äôt actually use variables in here otherwise.</p>
<pre><code class="hljs language-apache"><span class="hljs-attribute">ForceCommand</span> tmux attach
</code></pre>
<p>Finally we force the <code>tmux attach</code> command to run upon login. This makes
sure the user is connecting to the tmux session we‚Äôll start in the
following steps, and it‚Äôs important because we monitor the status of
this session to determine when to stop the server.</p>
<h2 id="start-sshd" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#start-sshd"><span>Start <code>sshd</code></span></a></h2>
<pre><code class="hljs language-sh">/usr/sbin/sshd -f sshd_config -D &amp;
sshd_pid=$!
</code></pre>
<ul>
<li>We need to start it with an absolute path (it is required when
starting an ad hoc SSH server like this).</li>
<li><code>-f</code> lets us specify the configuration file to use.</li>
<li><code>-D</code> starts it as foreground (by default it starts as a daemon).</li>
<li><code>&amp;</code> makes it a background process in this script so that we can fetch
its process ID with <code>$!</code> right after, and kill it at the end.</li>
</ul>
<p>We could avoid <code>-D</code> and <code>&amp;</code> altogether by using the <code>sshd.pid</code> file that
we configured in <code>PidFile</code> to retrieve the process ID instead. Whatever
works.</p>
<h2 id="start-a-tmux-session" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#start-a-tmux-session"><span>Start a tmux session</span></a></h2>
<pre><code class="hljs language-sh">(<span class="hljs-built_in">cd</span> <span class="hljs-string">&quot;<span class="hljs-variable">$GITHUB_WORKSPACE</span>&quot;</span> &amp;&amp; tmux new-session -d -s debug)
</code></pre>
<p>We start a subshell (the parens around the command), so that <code>cd</code> only
affects the subshell and not our top-level environment.</p>
<p>We effectively change the current directory to the main workflow
directory, defined in <code>GITHUB_WORKSPACE</code>, and start a tmux session.</p>
<p>With <code>tmux new-session</code>, <code>-d</code> disables the default behavior of
attaching the session to the current terminal, and <code>-s</code> allows us to
give it a name.</p>
<h2 id="start-cloudflared" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#start-cloudflared"><span>Start <code>cloudflared</code></span></a></h2>
<pre><code class="hljs language-sh">./cloudflared tunnel --no-autoupdate --url tcp://localhost:2222 &amp;
cloudflared_pid=$!
</code></pre>
<p>We run the <code>cloudflared</code> binary that we downloaded to the current
directory earlier. This command allows us to start a tunnel forwarding
to port 2222, where our SSH server is listening.</p>
<p>And again, we terminate with <code>&amp;</code> to start it as a background process so
that we can keep running commands and kill it at the end.</p>
<p>But there‚Äôs a few more things we need to add to this command:</p>
<pre><code class="hljs language-sh">./cloudflared tunnel ... 2&gt;&amp;1 | <span class="hljs-built_in">tee</span> cloudflared.log | sed -u <span class="hljs-string">&#x27;s/^/cloudflared: /&#x27;</span> &amp;
</code></pre>
<ul>
<li><code>2&gt;&amp;1</code> redirects the <code>stderr</code> output to <code>stdout</code>, so that we can
<code>tee</code> it to <code>cloudflared.log</code> file.</li>
<li><code>tee</code> will write the input to the given file, but also keep outputting
it to <code>stdout</code> at the same time.</li>
<li>This is great because we can now use a simple <code>sed</code> command to prefix
it with <code>cloudflared:</code> (so that the logs have some context).</li>
</ul>
<p>This log file is useful for us to retrieve the relay URL that
<code>cloudflared</code> will output, which we do right after:</p>
<pre><code class="hljs language-sh">url=$(<span class="hljs-built_in">head</span> -1 &lt;(<span class="hljs-built_in">tail</span> -f cloudflared.log | grep --line-buffered -o <span class="hljs-string">&#x27;https://.*\.trycloudflare.com&#x27;</span>))
</code></pre>
<ul>
<li><code>tail -f cloudflared.log</code> <em>follows</em> the file, meaning that it keeps
watching for new lines indefinitely, and outputs them as they come.</li>
<li>The <code>grep</code> command has a simple regex to identify the relay URL.
<ul>
<li><code>--line-buffered</code> is important here because we want to work <em>lazily</em>
and exit as soon as we find a match. If <code>grep</code> was buffering more
than one line of data, this could just hang forever.</li>
<li><code>-o</code> will print only the text matched by the regex instead of the
whole matching line.</li>
</ul>
</li>
<li>We put all of that in a subshell that we use as input to the <code>head</code>
command with the <code>&lt;()</code> syntax.</li>
<li><code>head -1</code> will exit the whole pipeline after one line is outputted,
allowing us to continue running the script.</li>
</ul>
<div class="note">
<p><strong>Note:</strong> we can‚Äôt put <code>head -1</code> at the end of the pipeline even though
that would seem intuitive, because it would take <code>grep</code> to try to
<em>write</em> to the <code>head</code> input after it was closed to notice that the pipe
was broken, and then it would take another line output from <code>tail</code> to
notice that <code>grep</code> exited.</p>
<p>In practice this just means this would hang indefinitely because
<code>cloudflared</code> doesn‚Äôt output the relay host twice.</p>
<p>See more details <a href="https://stackoverflow.com/questions/45326901/lazy-non-buffered-processing-of-shell-pipeline">here</a>.</p>
</div>
<h2 id="output-the-client-instructions" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#output-the-client-instructions"><span>Output the client instructions</span></a></h2>
<p>We already have the <code>url</code> variable as well as an optional <code>password</code>
variable.</p>
<p>With that, all we need is the SSH server public key to include it as
part of the connection command that the user will paste.</p>
<pre><code class="hljs language-sh">public_key=$(<span class="hljs-built_in">cut</span> -d<span class="hljs-string">&#x27; &#x27;</span> -f1,2 &lt; ssh_host_rsa_key.pub)
</code></pre>
<p>Thanks to the <code>cut</code> command, we split the single line in the given file
by space, and output only fields 1 and 2. This file normally has 3
fields: the key type, the actual key, and a comment. We don‚Äôt need the
comment.</p>
<p>We can then display those variables in a friendly and convenient way to
the user. I already detailed that in <a href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#details-of-the-client-connect-commands">the first part</a>
focusing on the client side, check it out if you didn‚Äôt already!</p>
<h2 id="watch-for-session-end" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#watch-for-session-end"><span>Watch for session end</span></a></h2>
<pre><code class="hljs language-sh">tmux wait-for channel
</code></pre>
<p>This commands waits for a channel named <code>channel</code> to be ‚Äúwoken up‚Äù by a
matching <code>tmux wait-for -S channel</code>.</p>
<p>We don‚Äôt actually ever run this last command, and we don‚Äôt really care
about the channel either, but the effect this have if we never ‚Äúwake up‚Äù
the channel, is that it will hang until the tmux session itself is over.</p>
<p>That‚Äôs exactly what we need: when the user is done debugging, they‚Äôll
typically end the tmux session, and this is our way to know we can tear
down the servers:</p>
<pre><code class="hljs language-sh"><span class="hljs-built_in">kill</span> <span class="hljs-string">&quot;<span class="hljs-variable">$cloudflared_pid</span>&quot;</span>
<span class="hljs-built_in">kill</span> <span class="hljs-string">&quot;<span class="hljs-variable">$sshd_pid</span>&quot;</span>
</code></pre>
<h2 id="wrapping-up" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html#wrapping-up"><span>Wrapping up</span></a></h2>
<p>And just like that, you know everything about
<a href="https://github.com/valeriangalliat/action-sshd-cloudflared">action-sshd-cloudflared</a>!</p>
<p>This script is simple enough to be explained in depth in a blog post,
and builds on top of rock solid programs like <code>sshd</code>, <code>cloudflared</code> and
tmux.</p>
<p>Thanks to Cloudflare Tunnel guest mode, we don‚Äôt even need an API key or
token to set up the relay, and because GitHub already exposes the actor
public SSH keys, we can preconfigure them so that everything just works
out of the box.</p>
<p>I hope GitHub introduces a SSH feature natively at some point, that
would make actions like this obsolete. In the meantime, I hope this
helps you debug your GitHub workflows!</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Join the discussion on <a href="https://twitter.com/valeriangalliat/status/1525554351648956416">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Debugging a GitHub Actions workflow via SSH</title>
    <link href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html" />
    <id>https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html</id>
    <updated>2022-05-14T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Since GitHub introduced <a href="https://github.com/features/actions">Actions</a>,
it‚Äôs more and more common to use them for CI/CD tasks, because of the
tight integration with GitHub, and its simplicity.</p>
<p>Coming from <a href="https://circleci.com/">CircleCI</a>, I was used to their
<a href="https://circleci.com/docs/2.0/ssh-access-jobs/">‚Äúrerun job with SSH‚Äù feature</a>,
which allowed to rerun a job while exposing a SSH server, to debug the
live test environment, and I was surprised to not find a similar feature
on GitHub Actions.</p>
<h2 id="why-ssh-to-the-ci-environment" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#why-ssh-to-the-ci-environment"><span>Why SSH to the CI environment?</span></a></h2>
<p>SSHing to CI is extremely handy in scenarios where <strong>a bug happens only
on CI</strong> and can‚Äôt be reproduced locally or on other staging servers we
have control over.</p>
<p>It can also be useful <strong>when initially setting up a GitHub Action</strong> for
your app when you‚Äôre not sure exactly what‚Äôs available in the GitHub
image, what versions, etc. and want to <strong>quickly fiddle around</strong> to find
the right instructions to set up the environment for success.</p>
<h2 id="what-about-containers" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#what-about-containers"><span>What about containers?</span></a></h2>
<p>The advent of containers should mitigate part of the problem, with more
and more apps being <a href="https://en.wiktionary.org/wiki/dockerize">‚Äúdockerized‚Äù</a>,
but the reality is that your GitHub Actions workflow
<a href="https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#choosing-github-hosted-runners">likely runs on <code>ubuntu-latest</code></a>
because that‚Äôs far more convenient, and that‚Äôs the main way that‚Äôs
documented basically everywhere. You‚Äôre still running in a container,
but that‚Äôs GitHub‚Äôs container, and it‚Äôs (very) different from your
development, staging and production containers.</p>
<p>And even if you <a href="https://docs.github.com/en/actions/using-jobs/running-jobs-in-a-container">bring your own container</a>,
you‚Äôre still likely to encounter <strong>differences inherent to running in a
CI environment</strong>: are the volumes and ports configured exactly the same?
What about the services you depend on like PostgreSQL, Redis, etc.? How
do you manage your environment variables? Are they any different from
your local environment? (They probably should.)</p>
<p>Also did you ever encounter timing-based bugs that <strong>only happen on a
slow machine</strong> (or network), or inversely, only happen <strong>when the code
runs too fast</strong>? I did. Both of those.</p>
<h2 id="introducing-action-sshd-cloudflared" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#introducing-action-sshd-cloudflared"><span>Introducing action-sshd-cloudflared</span></a></h2>
<p>This is why I created <a href="https://github.com/valeriangalliat/action-sshd-cloudflared">action-sshd-cloudflared</a>.</p>
<p>The idea? Find the <strong>simplest way to run a SSH server</strong> in a GitHub
Action and somehow connect to it. The last part can be a challenge
because as you can expect, the VM the workflow runs in <strong>doesn‚Äôt have a
public IP</strong>, and not even IPv6. No way to directly bind a port publicly
accessible from the internet.</p>
<p>That‚Äôs why we need to <strong>resort to a relay host</strong>. I chose
<a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/">Cloudflare Tunnel</a>
for that, which is convenient because it includes a way to
<a href="https://developers.cloudflare.com/cloudflare-one/applications/non-http/arbitrary-tcp/">forward abritrary TCP</a>,
and happily runs as guest (no need to be authenticated).</p>
<p>In the end, it takes <a href="https://github.com/valeriangalliat/action-sshd-cloudflared/blob/master/setup-ssh">100 lines of commented shell script</a>,
and if you‚Äôre interested in the details, I encourage you to read my
<a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html">explanation of how the server works</a>.</p>
<p>But for now, I‚Äôll start by <strong>showing you how to use it</strong>, then I‚Äôll
break down <strong>what the client-side commands do</strong>, and finally I‚Äôll
compare it to other options.</p>
<h2 id="usage" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#usage"><span>Usage</span></a></h2>
<p>Here‚Äôs an example workflow YAML file that does nothing but checking out
your repository and starting a SSH server.</p>
<pre><code class="hljs language-yaml"><span class="hljs-attr">name:</span> <span class="hljs-string">CI</span>
<span class="hljs-attr">on:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-string">push</span>
<span class="hljs-attr">jobs:</span>
  <span class="hljs-attr">build:</span>
    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span>
    <span class="hljs-attr">steps:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v2</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">valeriangalliat/action-sshd-cloudflared@v1</span>
</code></pre>
<p>More likely you already have a workflow YAML and the only part you care
about is to add this to your <code>steps</code> array:</p>
<pre><code class="hljs language-yaml">      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">valeriangalliat/action-sshd-cloudflared@v1</span>
</code></pre>
<p>From there, here‚Äôs an example output you‚Äôll find on your workflow logs:</p>
<pre><code class="hljs">Downloading `cloudflared` from &lt;https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64&gt;...
Configured SSH key(s) for user: valeriangalliat
Creating SSH server key...
Creating SSH server config...
Starting SSH server...
Starting tmux session...
Starting Cloudflare tunnel...

Run the following command to connect:

    ssh-keygen -R action-sshd-cloudflared &amp;&amp; echo &#x27;action-sshd-cloudflared ssh-rsa (public key goes here)&#x27; &gt;&gt; ~/.ssh/known_hosts &amp;&amp; ssh -o ProxyCommand=&#x27;cloudflared access tcp --hostname https://recycling-currently-enjoy-pregnant.trycloudflare.com&#x27; runner@action-sshd-cloudflared

What the one-liner does:

    # Remove old SSH server public key for `action-sshd-cloudflared`
    ssh-keygen -R action-sshd-cloudflared

    # Trust the public key for this session
    echo &#x27;action-sshd-cloudflared ssh-rsa (public key goes here)&#x27; &gt;&gt; ~/.ssh/known_hosts

    # Connect using `cloudflared` as a transport (SSH is end-to-end encrpted over this tunnel)
    ssh -o ProxyCommand=&#x27;cloudflared access tcp --hostname https://recycling-currently-enjoy-pregnant.trycloudflare.com&#x27; runner@action-sshd-cloudflared

    # Alternative if you don&#x27;t want to verify the host key
    ssh -o ProxyCommand=&#x27;cloudflared access tcp --hostname https://recycling-currently-enjoy-pregnant.trycloudflare.com&#x27; -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=accept-new runner@action-sshd-cloudflared
</code></pre>
<p>From there you can copy the (long, I know) one-liner that will connect
you to the VM. As you can see I also a commented version of the commands
for people to have a better understanding of what‚Äôs happening. Let‚Äôs go
through it in even more details.</p>
<h2 id="details-of-the-client-connect-commands" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#details-of-the-client-connect-commands"><span>Details of the client connect commands</span></a></h2>
<h3 id="remove-keys-from-previous-debugging-sessions" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#remove-keys-from-previous-debugging-sessions"><span>Remove keys from previous debugging sessions</span></a></h3>
<p>The first step is to remove all the keys matching host
<code>action-sshd-cloudflared</code> in <code>~/.ssh/known_hosts</code>. This is where your
SSH client stores the public keys of all the server you connected to.</p>
<pre><code class="hljs language-sh">ssh-keygen -R action-sshd-cloudflared
</code></pre>
<p>The reason we need to do this is because the fact the action generates a
new key every time it runs, we need to ‚Äúforget‚Äù any previous key as they
won‚Äôt be valid anymore. Otherwise SSH is confused and will prevent you
to connect to a host whose key is not the one it expects.</p>
<div class="note">
<p><strong>Note:</strong> an alternative would be to use a unique host every time (as
we‚Äôll see later, because of the way use a proxy command, we could put
any host in there), for example the same one that Cloudflare generated
for us (<code>https://recycling-currently-enjoy-pregnant.trycloudflare.com</code>
in the earlier example).</p>
<p>What I don‚Äôt like about that is every time you debug a GitHub workflow,
a new host will be added to your <code>~/.ssh/known_hosts</code> and this can
quickly pollute it. Sure, you can garbage collect them manually at some
point, but I‚Äôm still not a big fan of this idea.</p>
</div>
<h3 id="trust-the-key-for-the-current-session" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#trust-the-key-for-the-current-session"><span>Trust the key for the current session</span></a></h3>
<p>This step is not technically required, for if we don‚Äôt do it, the SSH
client will prompt you to trust the key when it first encounters it
(trust on first use model).</p>
<p>But here we‚Äôre already copy/pasting quite a long one-liner, so might as
well include an extra step to include the server public key and put it
in the known hosts file.</p>
<pre><code class="hljs language-sh"><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;action-sshd-cloudflared ssh-rsa (public key goes here)&#x27;</span> &gt;&gt; ~/.ssh/known_hosts
</code></pre>
<p>Trust on first use is fine, but this is better; would you really check
that the server key fingerprint matches what was shown in the server
logs otherwise?</p>
<h3 id="connect-to-the-cloudflare-tunnel" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#connect-to-the-cloudflare-tunnel"><span>Connect to the Cloudflare Tunnel</span></a></h3>
<p>It is the command we use as SSH <code>ProxyCommand</code>:</p>
<pre><code class="hljs language-sh">cloudflared access tcp --hostname https://recycling-currently-enjoy-pregnant.trycloudflare.com
</code></pre>
<p>This command if run by itself, will open a TCP connection to our SSH
server inside the GitHub VM, on port 2222 (the one we configured from
the other side of the Cloudflare Tunnel), through the relay that
Cloudflare gave us (the random subdomain on <code>trycloudflare.com</code>).</p>
<p>Everything written on <code>stdin</code> will be sent over the TCP socket, and
everything received will go to <code>stdout</code>. Simple as that.</p>
<p>The good thing is that this simple interface is supported by the <code>ssh</code>
command configure the underlying connection, with the <code>-o ProxyCommand</code>
flag.</p>
<h3 id="ssh-through-the-proxy" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#ssh-through-the-proxy"><span>SSH through the proxy</span></a></h3>
<p>This is the final piece of the puzzle:</p>
<pre><code class="hljs language-sh">ssh -o ProxyCommand=<span class="hljs-string">&#x27;cloudflared access tcp --hostname https://recycling-currently-enjoy-pregnant.trycloudflare.com&#x27;</span> runner@action-sshd-cloudflared
</code></pre>
<p>We explained already what the <code>cloudflared access tcp</code> command does, so
we‚Äôll focus on the rest:</p>
<pre><code class="hljs language-sh">ssh -o ProxyCommand=<span class="hljs-string">&#x27;...&#x27;</span> runner@action-sshd-cloudflared
</code></pre>
<p>Here we issue a SSH connection to host <code>action-sshd-cloudflared</code> with
user <code>runner</code>. But because of the <code>ProxyCommand</code> we configured, the
given host is not actually used, and we could put anything in there.</p>
<p>We could even connect to <code>runner@</code> (effectively no hostname), and that
would work. That being said this is not an ideal solution because it
would leave an entry in <code>~/.ssh/known_hosts</code> for a ‚Äúempty string‚Äù host,
and that‚Äôs not really useful. Putting <code>action-sshd-cloudflared</code> here is
more clear on what this key is related to.</p>
<p>The combination of both those commands effectively connects you to the
remote SSH server in the GitHub VM.</p>
<h2 id="what-about-action-upterm-and-action-tmate" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#what-about-action-upterm-and-action-tmate"><span>What about action-upterm and action-tmate?</span></a></h2>
<p>When I first tried to debug a GitHub workflow via SSH, I stumbled upon
two actions: <a href="https://github.com/marketplace/actions/debugging-with-ssh">debugging with SSH</a>
and <a href="https://github.com/marketplace/actions/debugging-with-tmate">debugging with tmate</a>,
also named <a href="https://github.com/lhotari/action-upterm">action-upterm</a>
and <a href="https://github.com/mxschmitt/action-tmate">action-tmate</a> in their
respective repos.</p>
<p>They‚Äôre both great and work perfectly for the task at hand, and can do
even more than that, because both <a href="https://upterm.dev/">Upterm</a>
and <a href="https://tmate.io/">tmate</a> are designed to <em>share</em> a terminal
session amongst multiple clients.</p>
<p>They both work by providing a client ‚Äúhost‚Äù software, and a public relay
server. The host uses the client to connect to the relay server and
share a terminal input and output with it, and other users can SSH to
that relay to access the shared session.</p>
<p>The advantage of the relay server in a world where most computers don‚Äôt
have a public IP address and probably not public IPv6 either, is to
enable <a href="https://en.wikipedia.org/wiki/NAT_traversal">NAT traversal</a> to
share a local service with the internet despite not being publicly
routable to. This is the problem that the famous
<a href="https://ngrok.com/">ngrok</a> is solving, or more simply, SSH TCP
forwarding (with the <code>-L</code> and <code>-R</code> options).</p>
<h3 id="the-problem-with-the-relay-server" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#the-problem-with-the-relay-server"><span>The problem with the relay server</span></a></h3>
<p>There‚Äôs one thing that bugs me very much with the way they both designed
the relay server: it‚Äôs not just acting as a TCP relay to enable NAT
traversal! Not only the server contains business logic, but for this
business logic to work, it needs plaintext access to the SSH connection
(as opposed to only forwarding encrypted TCP traffic).</p>
<p>This is very much a no-no for me. The good thing is that they both
provide a way to <a href="https://upterm.dev/#deploy-uptermd">host</a> your
<a href="https://tmate.io/#host">own</a> relay server, where it‚Äôs not as much of a
big deal that the relay sees plaintext traffic (it moves the trust from
‚Äúrandom strangers on the internet‚Äù to the entity you pay to host your
server, which is arguably an improvement, although far from end-to-end
encryption).</p>
<p>But I‚Äôm lazy, and that‚Äôs too much work anyways. Especially when I know a
bare <code>sshd</code> and a ‚Äúdumb‚Äù (here used in a positive sense) TCP relay would
do the job for me.</p>
<p>I would have been more keep to using Upterm or tmate if they moved all
the business logic to the host client software, and let the relay be‚Ä¶
a (dumb) TCP relay happily breaking NAT and forwarding encrypted traffic
around. But I reckon this can be a challenge especially with the
extended feature set those tools want to support.</p>
<h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/debugging-github-actions-workflow-ssh.html#conclusion"><span>Conclusion</span></a></h2>
<p>Overall, <code>sshd</code> and <code>cloudflared</code> work perfectly hand in hand to allow
SSHing in an otherwise unroutable GitHub workflow container.</p>
<p>This is the beauty of the Unix philosophy: tools that do one thing, and
do it well, and are <em>composable</em> through <em>universal interfaces</em>.</p>
<p>If you liked this post, you will definitely enjoy the second part where
I <a href="https://www.codejam.info/2022/05/github-action-expose-ssh-server.html">explain how action-sshd-cloudflared works internally</a>.
Cheers!</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Join the discussion on <a href="https://twitter.com/valeriangalliat/status/1525554350042619904">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Notion: import CSV with Markdown page content</title>
    <link href="https://www.codejam.info/2022/05/notion-csv-markdown-page-content.html" />
    <id>https://www.codejam.info/2022/05/notion-csv-markdown-page-content.html</id>
    <updated>2022-05-11T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>As I was <a href="https://github.com/valeriangalliat/github-to-notion">migrating a GitHub project to Notion</a>,
one of the solutions I considered was to import a CSV using the native
import feature.</p>
<p>Sadly, there was no way to set the page content from the rows in the CSV
file. All the columns are imported as custom attributes and we
can‚Äôt pick one to be used as page content.</p>
<p>So I ended up making a <a href="https://github.com/valeriangalliat/github-to-notion/blob/master/import-to-notion.js">custom script</a>
using the <a href="https://developers.notion.com/">Notion API</a>. And while this
script is very specific to my use case, I figured it would be good to
generalize it and go back to my original CSV idea, this way other people
can leverage it for their own projects!</p>
<h2 id="the-way-it-works" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/notion-csv-markdown-page-content.html#the-way-it-works"><span>The way it works</span></a></h2>
<p>The idea is simple. First, we import a CSV using the native import
feature, which results in our ‚Äúcontent‚Äù column being imported as a page
attribute. Then we run a simple scripts that goes through all the pages
with a non-empty ‚Äúcontent‚Äù column, and moves it to the page body
instead!</p>
<p>I named this script <a href="https://github.com/valeriangalliat/notion-property-to-content">Notion property to content</a>
(I know, I suck at naming things), and with a bit terminal fu, you can
use it on your own Notion imports!</p>
<h2 id="running-the-script" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/notion-csv-markdown-page-content.html#running-the-script"><span>Running the script</span></a></h2>
<p>It requires <a href="https://nodejs.org/">Node.js</a> version 18 or later.</p>
<pre><code class="hljs language-sh">git <span class="hljs-built_in">clone</span> https://github.com/valeriangalliat/notion-property-to-content
<span class="hljs-built_in">cd</span> notion-property-to-content
npm install
</code></pre>
<p>From there, we need a Notion token. For this, you need to
<a href="https://www.notion.so/my-integrations">create a new integration</a>. The
default parameters should do. At the end Notion will give you a token
that we‚Äôll set in an environment variable (lines starting with <code>$</code> means
an actual command that you run, but don‚Äôt type the <code>$</code>):</p>
<pre><code class="hljs language-console"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">read</span> NOTION_TOKEN</span>
Paste the token here
<span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">export</span> NOTION_TOKEN</span>
</code></pre>
<p>Now you need to share the database you‚Äôre working on with your newly
created integration. On the top right corner of your database page, hit
the ‚Äúshare‚Äù button:</p>
<figure class="center">
  <img src="https://www.codejam.info/img/2022/05/notion-share.png">
</figure>
<p>Click on the search field to reveal your integration, and click
‚Äúinvite‚Äù:</p>
<figure class="center">
  <img src="https://www.codejam.info/img/2022/05/notion-invite.png">
</figure>
<p>While you‚Äôre on the database page, copy its ID from the URL bar, for
example if the current URL is:</p>
<pre><code class="hljs">https://www.notion.so/513bff94c55a4cf09a66a336c87e7964?v=0eb7b11463c94c3a84786bd3191e4032
</code></pre>
<p>Copy this part:</p>
<pre><code class="hljs">513bff94c55a4cf09a66a336c87e7964
</code></pre>
<p>Finally, back to the terminal, you can run the following command to
move the property of your choice to the page content:</p>
<pre><code class="hljs language-sh">node property-to-content.js &lt;database-id&gt; &lt;property&gt; --remove
</code></pre>
<p>Where <code>&lt;database-id&gt;</code> is the ID of your database and <code>&lt;property&gt;</code> is the
name of the property you want to use as page content. For example if
your database ID is <code>513bff94c55a4cf09a66a336c87e7964</code> and your property
is named ‚ÄúPage Content‚Äù, run:</p>
<pre><code class="hljs language-sh">node property-to-content.js 513bff94c55a4cf09a66a336c87e7964 <span class="hljs-string">&#x27;Page Content&#x27;</span> --remove
</code></pre>
<div class="note">
<p><strong>Note:</strong> I recommend you to run this on a test database first just to
make sure it behaves the way you want with your data!</p>
</div>
<p>The <code>--remove</code> part is to empty the property after writing its value to
the actual page content. It is useful so that if you were to run the
script again, it doesn‚Äôt copy the content a second time at the end of
the page, as the script only goes through non-empty content values.</p>
<p>If you plan to only run this once and want to keep the content in its
original property, don‚Äôt add the <code>--remove</code> part.</p>
<h2 id="need-some-help" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/notion-csv-markdown-page-content.html#need-some-help"><span>Need some help?</span></a></h2>
<p>If you need help with this, or importing data to your Notion workspace
and working with the Notion API in general, don‚Äôt hesitate to
<a href="https://www.codejam.info/val.html#contact">shoot me an email</a>, I‚Äôll be happy to help you on a
consulting basis! You‚Äôll even get a 20% discount if you tell me you‚Äôre
coming from this article. üòú</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Start a conversation on <a href="https://twitter.com/valeriangalliat">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Google Cloud service account authorization without OAuth</title>
    <link href="https://www.codejam.info/2022/05/google-cloud-service-account-authorization-without-oauth.html" />
    <id>https://www.codejam.info/2022/05/google-cloud-service-account-authorization-without-oauth.html</id>
    <updated>2022-05-07T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Google‚Äôs <a href="https://developers.google.com/identity/protocols/oauth2/service-account">OAuth documentation</a>
goes in length about how to sign a JWT with the service account key in
order to call their token endpoint <code>https://oauth2.googleapis.com/token</code>
to get an OAuth token so that you can call actual Google Cloud APIs,
only to mention at the end in a small addendum that you can skip the
token endpoint step altogether and
<a href="https://developers.google.com/identity/protocols/oauth2/service-account#jwt-auth">just use your self-signed JWT directly</a>. üò¨</p>
<p>In this blog post we‚Äôll develop this last step, because it‚Äôs so much
more convenient, reliable, and there‚Äôs a few undocumented things about
it.</p>
<h2 id="the-normal-flow" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/google-cloud-service-account-authorization-without-oauth.html#the-normal-flow"><span>The normal flow</span></a></h2>
<p>But before, let‚Äôs quickly look at the ‚Äúnormal‚Äù recommended OAuth flow.
Borrowing this diagram from their documentation:</p>
<figure class="center">
  <img alt="JWT OAuth flow" src="https://www.codejam.info/img/2022/05/jwt-flow.png">
</figure>
<ol>
<li>Create a self-signed JWT using your service account key.</li>
<li>Use it to authenticate to <code>https://oauth2.googleapis.com/token</code> to
request an OAuth token.</li>
<li>Use that OAuth token to call Google APIs.</li>
</ol>
<p>This is not bad, but having to go over the network to authenticate and
refresh tokens before they expire adds extra overhead, delay, error
handling, retry logic, and in general just an extra few things that can
go wrong.</p>
<p>And I don‚Äôt like things out of my control that can go wrong.</p>
<h2 id="the-better-flow" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/google-cloud-service-account-authorization-without-oauth.html#the-better-flow"><span>The better flow</span></a></h2>
<p>On the other hand, the poorly documented ‚Äúservice account authorization
without OAuth method‚Äù consists in:</p>
<ol>
<li>Create a self-signed JWT using your service account key.</li>
<li>Use it directly to call Google APIs.</li>
<li>Profit.</li>
</ol>
<p>Same amount of steps, but you can imagine why I like this method better.</p>
<h2 id="implementing-direct-authorization-from-scratch" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/google-cloud-service-account-authorization-without-oauth.html#implementing-direct-authorization-from-scratch"><span>Implementing direct authorization from scratch</span></a></h2>
<p>Typically, the Google Cloud SDK in the language of your choice takes
care of this for you (and most of the time uses this self-signed method,
because they too realize it‚Äôs a much superior method). But in some
cases, you have to reimplement the authorization step, for example
<a href="https://hookdeck.com/blog/post/how-to-call-google-cloud-apis-from-cloudflare-workers#the-problem-with-cloudflare-workers">when running on Cloudflare Workers</a>,
which I wrote about in details in that article.</p>
<p>As of today their <a href="https://developers.google.com/identity/protocols/oauth2/service-account#jwt-auth">documentation</a>
mentions the JWT must have the following header and payload:</p>
<pre><code class="hljs language-json"><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;alg&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;RS256&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;typ&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;JWT&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;kid&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;SERVICE_ACCOUNT_PRIVATE_KEY_ID&quot;</span>
<span class="hljs-punctuation">}</span>
.
<span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;iss&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;SERVICE_ACCOUNT_EMAIL&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;sub&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;SERVICE_ACCOUNT_EMAIL&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;aud&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;https://SERVICE.googleapis.com/&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;iat&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1511900000</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;exp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1511903600</span>
<span class="hljs-punctuation">}</span>
</code></pre>
<p>Where the parts in all caps are variables to adapt to your situation.
Then the JWT can be signed with RS256 (RSA signature with SHA-256), and
used in a <code>Authorization: Bearer</code> header against the service you
included in the <code>aud</code> field.</p>
<p>And it does work most of the time (again checkout <a href="https://hookdeck.com/blog/post/how-to-call-google-cloud-apis-from-cloudflare-workers#the-problem-with-cloudflare-workers">my post</a>
to see the vanilla JavaScript implementation), but in some cases like
with Google Cloud Storage, <a href="https://stackoverflow.com/q/63222450">it breaks down</a>.</p>
<h2 id="when-it-breaks-down" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/google-cloud-service-account-authorization-without-oauth.html#when-it-breaks-down"><span>When it breaks down</span></a></h2>
<p>With Google Cloud Storage, when using the documented method with a <code>aud</code>
field of <code>https://storage.googleapis.com/</code>, we sadly <a href="https://stackoverflow.com/q/63222450">get an error</a>
when calling the API, e.g. when trying to get a file:</p>
<pre><code class="hljs language-xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span> encoding=<span class="hljs-string">&quot;UTF-8&quot;</span>?&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-name">Error</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">Code</span>&gt;</span>AuthenticationRequired<span class="hljs-tag">&lt;/<span class="hljs-name">Code</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">Message</span>&gt;</span>Authentication required.<span class="hljs-tag">&lt;/<span class="hljs-name">Message</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">Error</span>&gt;</span>
</code></pre>
<p>Or when trying to upload a file:</p>
<pre><code class="hljs language-json"><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;error&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;code&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">401</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;message&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Invalid Credentials&quot;</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;errors&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
      <span class="hljs-punctuation">{</span>
        <span class="hljs-attr">&quot;message&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Invalid Credentials&quot;</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;domain&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;global&quot;</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;reason&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;authError&quot;</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;locationType&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;header&quot;</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;location&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Authorization&quot;</span>
      <span class="hljs-punctuation">}</span>
    <span class="hljs-punctuation">]</span>
  <span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">}</span>
</code></pre>
<p>But the exact same code to generate a JWT works seamlessly with Pub/Sub,
Datastore and other services! Why is that? Should we fall back to using
the OAuth endpoint for those problematic services?</p>
<p>No.</p>
<h2 id="the-new-undocumented-jwt-payload" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/google-cloud-service-account-authorization-without-oauth.html#the-new-undocumented-jwt-payload"><span>The new, undocumented JWT payload</span></a></h2>
<p>It turns out that you need to remove the <code>aud</code> field and replace it with
a <code>scope</code> field, akin to the one we would pass to the main OAuth token
endpoint.</p>
<p>In the case of Google Cloud Storage, our JWT payload would now look like
this:</p>
<pre><code class="hljs language-json"><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;iss&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;SERVICE_ACCOUNT_EMAIL&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;sub&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;SERVICE_ACCOUNT_EMAIL&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;scope&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;https://www.googleapis.com/auth/iam https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/devstorage.full_control&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;iat&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1511900000</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;exp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1511903600</span>
<span class="hljs-punctuation">}</span>
</code></pre>
<p>You can find the <a href="https://developers.google.com/identity/protocols/oauth2/scopes">full list of OAuth scopes</a>
in the Google Cloud OAuth 2.0 documentation.</p>
<p>It turns out the <code>scope</code> field is also accepted by Pub/Sub and other
services that were working fine with <code>aud</code>, so we can just make our
generic implementation use the <code>scope</code> field and be done with it. Sweet!</p>
<h2 id="bonus-how-did-i-find-out-about-that" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/google-cloud-service-account-authorization-without-oauth.html#bonus-how-did-i-find-out-about-that"><span>Bonus: how did I find out about that?</span></a></h2>
<p>This is the story about <a href="https://stackoverflow.com/a/71834557">this answer</a>
I posted on the Stack Overflow question I linked earlier.</p>
<p>First, I dug in the <a href="https://github.com/googleapis/google-cloud-node">Google Cloud Node.js SDK</a>
to see how they implemented the service account authentication.</p>
<p>It turns out they do use the <a href="https://github.com/googleapis/google-auth-library-nodejs/blob/b48254490768799e465a8fa4aae13296ddceea53/src/auth/jwtclient.ts#L126">self-signed JWT method</a>,
in their shared auth library, but it‚Äôs conditional to a variable
<code>useJWTAccessWithScope</code> being set to <code>true</code> by the client SDK. For
example, this is <a href="https://github.com/googleapis/nodejs-pubsub/blob/ba333c2284b802cdd43df7568b553b2a90dba8d8/src/v1/publisher_client.ts#L139">where Pub/Sub sets it</a>,
and this is
<a href="https://github.com/googleapis/nodejs-storage/search?q=useJWTAccessWithScope">where GCS <strong>doesn‚Äôt</strong> set it</a>
(as of today).</p>
<p>But what if we force this variable to <code>true</code>?</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> { <span class="hljs-title class_">Storage</span> } <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;@google-cloud/storage&#x27;</span>

<span class="hljs-keyword">const</span> storage = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Storage</span>()

storage.<span class="hljs-property">authClient</span>.<span class="hljs-property">useJWTAccessWithScope</span> = <span class="hljs-literal">true</span>

<span class="hljs-keyword">const</span> file = <span class="hljs-keyword">await</span> storage.<span class="hljs-title function_">bucket</span>(<span class="hljs-string">&#x27;bucket&#x27;</span>).<span class="hljs-title function_">file</span>(<span class="hljs-string">&#x27;file&#x27;</span>).<span class="hljs-title function_">get</span>()
</code></pre>
<p>By running this script with <code>NODE_DEBUG=https</code>, we can see that without
the <code>useJWTAccessWithScope</code> line, the client makes a call to
<code>https://www.googleapis.com/oauth2/v4/token</code> first, then calls
<code>https://storage.googleapis.com/storage/v1/b/bucket/o/file</code>, but with
<code>useJWTAccessWithScope</code>, it skips the first token call (and everything
works still)!</p>
<p>We can also notice that the token from the OAuth token endpoint contains
hundreds of dots (<code>.</code>) at the end, whereas the self-signed token is just
the usual 3 parts Base64URL JWT. Not an useful information, but
interesting.</p>
<p>Either way, this proved that despite not working with the method in the
documentation, self-signed authentication was effectively supported by
Google Cloud Storage. So how did that SDK-generated token differ? The
easiest is to copy that token from our <code>NODE_DEBUG=https</code> output and
parse the payload segment:</p>
<pre><code class="hljs language-sh">pbpaste | <span class="hljs-built_in">cut</span> -d. -f2 | <span class="hljs-built_in">base64</span> --decode
</code></pre>
<p>Or in Node.js:</p>
<pre><code class="hljs language-js"><span class="hljs-title class_">Buffer</span>.<span class="hljs-title function_">from</span>(token.<span class="hljs-title function_">split</span>(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">1</span>], <span class="hljs-string">&#x27;base64&#x27;</span>).<span class="hljs-title function_">toString</span>()
</code></pre>
<p>There we see they use a <code>scope</code> parameter as opposed to <code>aud</code>.</p>
<p>We can track it down to the <a href="https://github.com/googleapis/google-auth-library-nodejs/blob/b48254490768799e465a8fa4aae13296ddceea53/src/auth/jwtclient.ts#L191">code of the authentication library</a>,
and we can also see where the Google Cloud Storage client
<a href="https://github.com/googleapis/nodejs-storage/blob/c3240060b3dc905013ab6fa219e975631b41f5c4/src/storage.ts#L653">defines the necessary OAuth scopes</a>.</p>
<h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/google-cloud-service-account-authorization-without-oauth.html#conclusion"><span>Conclusion</span></a></h2>
<p>With some investigation in the Google Cloud Node.js SDK source code and
some <code>NODE_DEBUG=https</code> debugging, we can dissect their implementation
of the self-signed service account authentication, and replicate it on
our side.</p>
<p>This enables us to use this simpler and superior mechanism that Google
uses internally, instead of the method that‚Äôs widely documented of
calling their OAuth endpoint.</p>
<p>I hope that you learnt something thanks to this article, and that it
helps you build great things! And as always, keep hacking! üöÄ</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Join the discussion on <a href="https://twitter.com/valeriangalliat/status/1523114655698554880">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>The disk wasn‚Äôt ejected because one or more programs may be using it</title>
    <link href="https://www.codejam.info/2022/05/macos-disk-not-ejected-programs-using-it.html" />
    <id>https://www.codejam.info/2022/05/macos-disk-not-ejected-programs-using-it.html</id>
    <updated>2022-05-05T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>If you run macOS, you might have run in the following error message when
trying to eject a removable device:</p>
<figure class="center">
  <img alt="The disk wasn‚Äôt ejected because one or more programs may be using it" src="https://www.codejam.info/img/2022/05/macos-disk-eject.png">
</figure>
<p>In some cases, even waiting a few minutes doesn‚Äôt solve the problem.
Often, it happens after deleting files from the device just before
ejecting, and Quick Look is often the culprit. Let‚Äôs see.</p>
<p><em>Inspired by <a href="https://mycyberuniverse.com/macos/how-fix-volume-cant-be-ejected-because-currently-use-user.html">this post</a>
and <a href="https://mycyberuniverse.com/macos/how-fix-volume-cant-be-ejected-because-currently-use.html">this post</a>.</em></p>
<h2 id="investigating" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/macos-disk-not-ejected-programs-using-it.html#investigating"><span>Investigating</span></a></h2>
<p>To know what program is currently using the volume you‚Äôre trying to
eject, you can use the <a href="https://linux.die.net/man/8/lsof"><code>lsof(8)</code></a>
command. In my case the volume is <code>/Volumes/LUMIX</code>:</p>
<pre><code class="hljs language-console"> lsof +c0 /Volumes/LUMIX
COMMAND            PID USER   FD   TYPE DEVICE   SIZE/OFF   NODE NAME
QuickLookUIService 611  val    3r   REG   1,31 2970637594     51 /Volumes/LUMIX/.Trashes/501/P2770021.MP4
</code></pre>
<div class="note">
<p><strong>Note:</strong> the <code>+c0</code> option here is to display the full command string.
By default, it only shows 9 characters.</p>
</div>
<p>You can see that <code>QuickLookUIService</code> is still doing something with the
file <code>P2770021.MP4</code> that I deleted‚Ä¶ and it‚Äôs probably stuck and
confused because the file is not there anymore.</p>
<h2 id="killing" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/macos-disk-not-ejected-programs-using-it.html#killing"><span>Killing</span></a></h2>
<p>To fix that, we can kill the <code>QuickLookUIService</code> process (or whatever
process was blocking in your case).</p>
<div class="note">
<p><strong>Note:</strong> in the case of <code>QuickLookUIService</code>, it‚Äôs safe to kill, but if
you‚Äôre dealing with a different program preventing you to eject your
drive, it‚Äôs up to your own judgment whether it‚Äôs a good idea or not to
kill it!</p>
</div>
<p>There‚Äôs essentially two methods we‚Äôll talk about: soft kill, which would
be<code>pkill QuickLookUIService</code> and hard kill, with <code>pkill -9 QuickLookUIService</code>.</p>
<p>In the case of this bug, it looks like we need to resort to hard kill,
as a soft kill doesn‚Äôt terminate the hanging process:</p>
<pre><code class="hljs language-sh">pkill -9 QuickLookUIService
</code></pre>
<p>Now you should be able to eject your device!</p>
<h2 id="restarting-quick-look" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/macos-disk-not-ejected-programs-using-it.html#restarting-quick-look"><span>Restarting Quick Look</span></a></h2>
<p>Quick Look is the macOS service responsible for computing file previews
for various UI components. After we killed it, it might or might not
restart by itself, so if you notice that new file previews and
thumbnails don‚Äôt appear anymore in your Finder, you can restart Quick
Look with the following command:</p>
<pre><code class="hljs language-sh">qlmanage -r
</code></pre>
<p>It won‚Äôt hurt to run it either way after killing the process and
ejecting the drive.</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Start a conversation on <a href="https://twitter.com/valeriangalliat">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>macOS faster switch between desktops and faster Dock</title>
    <link href="https://www.codejam.info/2022/05/macos-faster-desktops-dock.html" />
    <id>https://www.codejam.info/2022/05/macos-faster-desktops-dock.html</id>
    <updated>2022-05-05T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Quick tip for macOS! I‚Äôve always found the animation to switch between
desktops and spaces quite slow, when using <kbd>Ctrl</kbd> +
<kbd>Left</kbd> or <kbd>Right</kbd>, or using the 3 fingers swipe on a
trackpad.</p>
<p>Same thing when configuring the Dock to hide by default and only show
when the mouse is near it. There‚Äôs a slight delay that just drives me
nuts and caused me to keep the Dock visible at all times, wasting
precious vertical screen real estate! But luckily, I‚Äôve found solutions
for those two problems.</p>
<div class="note">
<p><strong>Note:</strong> initially I shared those on Twitter,
<a href="https://twitter.com/valeriangalliat/status/1519696597940158464">here</a>
for the Dock and
<a href="https://twitter.com/valeriangalliat/status/1519698499927158787">here</a>
for switching between desktops.</p>
</div>
<p>For the Dock, the delay can be removed with this command:</p>
<pre><code class="hljs language-sh">defaults write com.apple.dock autohide-delay -<span class="hljs-built_in">float</span> 0; killall Dock
</code></pre>
<p>And to switch faster between desktops, I found that macOS provides
Mission Control shortcuts to switch to a specific desktop directly. It‚Äôs
just not enabled by default, and you need to have multiple <em>active</em>
desktops in order for those shortcuts to be even shown in the
preferences!</p>
<p>For example with 3 active desktops, opening the keyboard shortcut
preferences, in the Mission Control section:</p>
<figure class="center">
  <img alt="macOS keyboard shortcuts" src="https://www.codejam.info/img/2022/05/macos-keyboard-shortcuts.png">
</figure>
<p>We see we can activate <kbd>Ctrl</kbd> and the number keys to directly
switch to a given desktop.</p>
<p>And it turns out the animation when using those shortcuts is noticeably
faster than <kbd>Ctrl</kbd> + <kbd>Left</kbd> and <kbd>Right</kbd>! And
on top of that instead of having to navigate through all the desktops
one by one, we can jump to the one we want directly, which makes the
flow even faster.</p>
<p>Sadly this doesn‚Äôt work with spaces (e.g. full screen windows), only
with desktops. Because of that, I switched from using iTerm2 and Visual
Studio Code in full screen, and I instead use them as a maximized window
in a new desktop. I lose a tiny bit of vertical space because of the top
bar, but I gained even more vertical space with the Dock trick earlier
that this is not a big deal!</p>
<p>I hope this tip was useful to you. ü•∞</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Start a conversation on <a href="https://twitter.com/valeriangalliat">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>Firefox credit card autofill not working on Linux</title>
    <link href="https://www.codejam.info/2022/05/firefox-credit-card-autofill-not-working-on-linux.html" />
    <id>https://www.codejam.info/2022/05/firefox-credit-card-autofill-not-working-on-linux.html</id>
    <updated>2022-05-05T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Firefox 79 <a href="https://techdows.com/2020/07/firefox-autofiil-credit-card.html">introduced</a>
credit card autofill capability back in summer 2020. The feature is
limited to a few regions, starting with US, and now supporting US, CA,
UK, FR and DE.</p>
<p>Today, I‚Äôm using Firefox 101 in Canada, and I noticed this feature
wasn‚Äôt working on my Linux computer. In this post I‚Äôll show what the
problem was, how I debugged it and especially how I fixed it!</p>
<h2 id="symptoms" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/firefox-credit-card-autofill-not-working-on-linux.html#symptoms"><span>Symptoms</span></a></h2>
<p>I know I have a few credit cards saved in my Firefox Sync account, they
work perfectly on macOS and Android versions of Firefox, and Firefox was
configured to sync them. Yet, the ‚Äúsaved credit cards‚Äù window in the
privacy preferences pane was empty!</p>
<figure class="center">
  <img alt="Empty credit cards window" src="https://www.codejam.info/img/2022/05/firefox-saved-credit-cards.png">
</figure>
<p>Also if I clicked the <kbd>Add‚Ä¶</kbd> button and try to add a credit
card (e.g. <code>4111111111111111</code> for a Visa card to pass the validation for
testing), the <kbd>Save</kbd> button was completely unresponsive.</p>
<h2 id="debugging" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/firefox-credit-card-autofill-not-working-on-linux.html#debugging"><span>Debugging</span></a></h2>
<p>I opened the browser console from ‚Äúmore tools‚Äù in the application menu.
Every time I clicked <kbd>Save</kbd>, an error would pop: ‚ÄúUser canceled
OS unlock entry‚Äù.</p>
<pre><code class="hljs">[Exception... &quot;User canceled OS unlock entry&quot; nsresult: &quot;0x80004004 (NS_ERROR_ABORT)&quot; location: &quot;JS frame :: resource://gre/modules/OSKeyStore.jsm :: encrypt :: line 332&quot; data: no] OSKeyStore.jsm:332:24
</code></pre>
<p>Luckily this problem is already reported <a href="https://bugs.archlinux.org/task/74373">on the Arch Linux bug tracker</a>,
and the solution seems to be to install a software providing
<code>org.freedesktop.secrets</code>, which as of today is either <code>gnome-keyring</code>
or <code>keepassxc</code>.</p>
<p>I installed <code>gnome-keyring</code> and had to reboot for it to start
automatically (ain‚Äôt no time to figure how this thing work under the
hood for now). Yet the bug persisted, despite people on that thread
mentioning this solves the issue for them!</p>
<p>The ‚ÄúUser canceled OS unlock entry‚Äù exception is thrown
during the <a href="https://github.com/mozilla/gecko-dev/blob/bf243bc817f97b0bb74af710bd9d874370468e8b/toolkit/modules/OSKeyStore.jsm#L333"><code>OSKeyStore.encrypt</code></a>
call, because the <code>ensureLoggedIn</code> function determined we were not
authenticated. The underlying reason seemed to be the
<a href="https://github.com/mozilla/gecko-dev/blob/bf243bc817f97b0bb74af710bd9d874370468e8b/toolkit/modules/OSKeyStore.jsm#L254"><code>nativeOSKeyStore.asyncGenerateSecret</code></a>
call returning <code>NS_ERROR_FAILURE</code>.</p>
<p>More likely Firefox wasn‚Äôt able to generate a secret in GNOME Keyring.
So I installed <a href="https://en.wikipedia.org/wiki/Seahorse_(software)">Seahorse</a>
to test it myself, and indeed, I couldn‚Äôt store new secrets from there
either, it would fail with <code>No such secret collection at path: /</code>. This
bug is also <a href="https://wiki.archlinux.org/title/GNOME/Keyring#No_such_secret_collection_at_path:_/">documented</a>
on the ArchWiki, but sadly the solution there didn‚Äôt work for me.</p>
<h2 id="the-underlying-issue" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/firefox-credit-card-autofill-not-working-on-linux.html#the-underlying-issue"><span>The underlying issue</span></a></h2>
<p>I use LightDM autologin to automatically start my compositor on boot
(where I <a href="https://www.codejam.info/2021/08/lock-screen-as-login-screen-linux.html">greet myself with a lock screen</a>).
It turns out GNOME Keyring doesn‚Äôt play well with autologin. From the
<a href="https://wiki.archlinux.org/title/GNOME/Keyring#Using_the_keyring">ArchWiki</a>:</p>
<blockquote>
<p>To use automatic unlocking with automatic login, you can set a blank
password for the default keyring. Note that the contents of the
keyring are stored unencrypted in this case.</p>
</blockquote>
<p>That‚Äôs not ideal. And I already have a primary password configured in
Firefox so it would suck to set a second one on GNOME Keyring just for
Firefox to deal with credit cards differently‚Ä¶</p>
<p>In the end I decided to ditch my automatic login and go back to TTY
login and <a href="https://wiki.archlinux.org/title/Sway#Automatically_on_TTY_login">starting Sway automatically upon login on TTY1</a>.
This is the recommended way to start Sway anyway, and they officially
don‚Äôt support display managers, so that definitely can‚Äôt hurt.</p>
<p>All I had to do was to edit <code>/etc/pam.d/login</code> according to the ‚Äúwhen
using console-based login‚Äù instructions of the <a href="https://wiki.archlinux.org/title/GNOME/Keyring#PAM_step">PAM
step</a> in the
GNOME Keyring page on ArchWiki, appending the following:</p>
<pre><code class="hljs">auth       optional     pam_gnome_keyring.so
session    optional     pam_gnome_keyring.so auto_start
</code></pre>
<h2 id="the-keepassxc-alternative" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/firefox-credit-card-autofill-not-working-on-linux.html#the-keepassxc-alternative"><span>The KeePassXC alternative</span></a></h2>
<p>In the bug tracker there‚Äôs also <a href="https://bugs.archlinux.org/task/74373#comment207641">an answer</a>
describing how to fix this issue with KeePassXC:</p>
<blockquote>
<ol>
<li>KeePassXC needs to be running.</li>
<li>The secret service integration must be enabled in settings.</li>
<li>A database must be setup where at least one group is accessible to the secret service.</li>
</ol>
</blockquote>
<p>That‚Äôs a solid alternative, but then if I want secrets to be properly
secured, I need to add another password to that KeePassXC database, on
top of my encrypted filesystem password, login password and Firefox
primary password. That starts to be quite a lot of passwords‚Ä¶ so I‚Äôll
stick with GNOME Keyring for now because it‚Äôs able to reuse my login
password for that purpose.</p>
<h2 id="final-words" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/05/firefox-credit-card-autofill-not-working-on-linux.html#final-words"><span>Final words</span></a></h2>
<p>I now have a successful credit card sync and autofill in Firefox on
Linux! I hope this becomes a bit simpler in the future, but at least I
learnt a thing or two about the underlying implementation and the
technical challenges and tradeoffs it involves.</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Start a conversation on <a href="https://twitter.com/valeriangalliat">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
  <entry>
    <title>graftcp: inspect any program‚Äôs HTTPS traffic through a proxy!</title>
    <link href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html" />
    <id>https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html</id>
    <updated>2022-04-30T04:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Recently, I <a href="https://www.codejam.info/2022/04/vanta-agent-m1-mac-without-rosetta.html#spying-on-the-spyware-and-monitoring-its-network-traffic">needed to sniff an app‚Äôs HTTPS traffic</a>.</p>
<p>While sniffing plaintext HTTP traffic is easy, by targeting the
transport layer with tools like <a href="https://linux.die.net/man/8/tcpdump"><code>tcpdump(8)</code></a>
or Wireshark, <em>HTTPS is another beast</em>.</p>
<p>Because of the TLS encryption, all we see at the transport layer is a
bunch of unusable encrypted data (and that‚Äôs the whole point of HTTPS).
So we need to resort to solutions at a higher layer in the stack.</p>
<p>My go-to for this kind of task is <a href="https://mitmproxy.org/">mitmproxy</a>,
an interactive HTTPS proxy, as well as its headless counterpart
<em>mitmdump</em>.</p>
<p>But those are only half of the solution. A proxy server is useless until
we route HTTPS traffic <em>through it</em>. And depending on the context, this
task can go from pretty trivial to quite tricky.</p>
<h2 id="common-ways-to-configure-a-proxy" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html#common-ways-to-configure-a-proxy"><span>Common ways to configure a proxy</span></a></h2>
<p>There‚Äôs 3 main ways that you can use to configure a proxy:</p>
<ol>
<li>the OS level,</li>
<li>the application level,</li>
<li>the environment level.</li>
</ol>
<p>I already <a href="https://www.codejam.info/2021/07/intercept-macos-app-traffic-mitmproxy.html">gave an introduction to mitmproxy</a>
last year on the blog, in which I explored <a href="https://www.codejam.info/2021/07/intercept-macos-app-traffic-mitmproxy.html#first-try-macos-network-proxy-settings">the OS level</a>
and <a href="https://www.codejam.info/2021/07/intercept-macos-app-traffic-mitmproxy.html#second-try-spotify-supports-app-level-proxy-settings">the app level</a>,
but I‚Äôll give a quick refresher here.</p>
<h3 id="the-os-level" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html#the-os-level"><span>The OS level</span></a></h3>
<p>Your OS usually lets you configure a proxy in the networking settings.
For example on macOS it‚Äôs in the advanced network preferences, and on
Android it‚Äôs in the advanced Wi-Fi settings.</p>
<p>It‚Äôs a good way to globally configure a proxy, but there‚Äôs no guarantee
that apps are going to respect it. Typically, the default browser that
ships with the OS (e.g. Safari) will use it, and some third-party
browsers might too, but in general most other apps just ignore it. Not
so good.</p>
<h3 id="the-application-level" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html#the-application-level"><span>The application level</span></a></h3>
<p>While most apps don‚Äôt respect OS-level proxy configuration, some can
provide you with a way to configure a proxy at their own level.</p>
<p>Typically this will be Firefox‚Äôs connection settings, with its very own
proxy configuration, Spotify‚Äôs advanced settings that <a href="https://www.codejam.info/2021/07/intercept-macos-app-traffic-mitmproxy.html#second-try-spotify-supports-app-level-proxy-settings">let you configure a proxy</a>,
or more recently I‚Äôve explored <a href="https://www.codejam.info/2022/04/vanta-agent-m1-mac-without-rosetta.html#the-proxy-hostname-argument">the <code>--proxy_hostname</code> argument</a>
to the <code>osqueryd</code> program.</p>
<p>But it‚Äôs up to the app‚Äôs developers to decide if they want or not to let
you configure a proxy, and how rigorously they use it‚Ä¶ (they might use
the proxy for some requests but not all of them).</p>
<h3 id="the-environment-level" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html#the-environment-level"><span>The environment level</span></a></h3>
<p>Finally, there are two pretty commonly used environment variables
(although I believe not standard per se) to configure a proxy:
<code>http_proxy</code> and <code>https_proxy</code>. They respectively configure a proxy to
route HTTP and HTTPS traffic through.</p>
<p>For example the Python language <a href="https://github.com/python/cpython/blob/a03a09e068435f47d02649dda93988dc44ffaaf1/Lib/urllib/request.py#L2507">supports those</a>
in its native <code>urllib</code> package, and while Node.js <a href="https://github.com/nodejs/node/issues/8381">doesn‚Äôt</a>,
the popular <a href="https://github.com/axios/axios">axios</a> library
<a href="https://github.com/axios/axios/blob/bc733fec78326609e751187c9d453cee9bf1993a/lib/adapters/http.js#L186">also supports them</a>
out of the box.</p>
<p>So basically, it might or might not work depending on the implementation
of the software that you‚Äôre using, but it‚Äôs definitely worth trying!</p>
<h2 id="when-nothing-works-the-hacker-way" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html#when-nothing-works-the-hacker-way"><span>When nothing works: the hacker way</span></a></h2>
<p>So far all we‚Äôve done is configuring a proxy in interfaces that
explicitly allow us to set a proxy. But sometimes this is just not
enough. That‚Äôs when we resort to ways to configure a proxy in places
that don‚Äôt explicitly let us do so. üòè</p>
<p>There‚Äôs two ways to do this. The most common one is to leverage
<code>LD_PRELOAD</code> with dynamically linked binaries to override symbols in a
library. This is the approach that <a href="https://linux.die.net/man/8/tsocks"><code>tsocks(1)</code></a>,
<a href="https://github.com/haad/proxychains">ProxyChains</a> and <a href="https://github.com/rofl0r/proxychains-ng">ProxyChains-NG</a>
use, hijacking the <a href="https://linux.die.net/man/2/connect"><code>connect(2)</code></a>
<a href="https://en.wikipedia.org/wiki/C_standard_library">libc</a> function to
route requests through the proxy of your choice.</p>
<p>This is a great method when using programs that are dynamically linked
against libc, but it will fail for statically liked programs, as well as
programs that don‚Äôt use libc (Go programs for example).</p>
<p>This is where <a href="https://github.com/hmgle/graftcp">graftcp</a> shines.
Instead of hooking at the libc level, it leverages
<a href="https://linux.die.net/man/2/ptrace"><code>ptrace(2)</code></a> to modify the
<a href="https://linux.die.net/man/3/connect"><code>connect(3)</code></a> syscall arguments!
Essentially, it‚Äôs acting at a lower level and that‚Äôs how it‚Äôs able to
proxy against statically liked programs that don‚Äôt use libc. Their
detailed <a href="https://github.com/hmgle/graftcp#principles">how does it work</a>
explanation is really worth a read.</p>
<h3 id="installation" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html#installation"><span>Installation</span></a></h3>
<pre><code class="hljs language-sh">git <span class="hljs-built_in">clone</span> https://github.com/hmgle/graftcp.git
<span class="hljs-built_in">cd</span> graftcp
make
</code></pre>
<h3 id="usage" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html#usage"><span>Usage</span></a></h3>
<p>From there, you can use <code>local/graftcp-local</code> to start the graftcp
server, and configure it to use your proxy (for example mitmproxy
starts a HTTP proxy on port 8080 by default). Because graftcp also
defaults to a SOCKS5 proxy on <code>localhost:1080</code>, we need to force it to
use the HTTP proxy we configured by using <code>--select_proxy_mode only_http_proxy</code>:</p>
<pre><code class="hljs language-sh"><span class="hljs-built_in">local</span>/graftcp-local --http_proxy localhost:8080 --select_proxy_mode only_http_proxy
</code></pre>
<p>We can do the same thing by ‚Äúemptying‚Äù the preconfigured SOCKS5 proxy:</p>
<pre><code class="hljs language-sh"><span class="hljs-built_in">local</span>/graftcp-local --http_proxy localhost:8080 --socks5 <span class="hljs-string">&#x27;&#x27;</span>
</code></pre>
<p>Or we can instead run mitmproxy as a SOCKS5 proxy, here on port 1080
(the default for graftcp):</p>
<pre><code class="hljs language-sh">mitmproxy --mode socks5 -p 1080
</code></pre>
<p>Then we can run <code>local/graftcp-local</code> without arguments and it‚Äôll just
work.</p>
<p>Either way, once the proxy and <code>local/graftcp-local</code> program is started,
we can prefix any command with <code>./graftcp</code> to force it to run its
network calls through the proxy!</p>
<pre><code class="hljs language-sh">./graftcp curl https://www.codejam.info/
</code></pre>
<h3 id="dealing-with-certificates" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html#dealing-with-certificates"><span>Dealing with certificates</span></a></h3>
<p>However, this should complain that the SSL certificate from mitmproxy is
untrusted. We can make it go through by appending <code>-k</code> (<code>--insecure</code>) to
the <code>curl</code> command:</p>
<pre><code class="hljs language-sh">./graftcp curl https://www.codejam.info/ --insecure
</code></pre>
<p>A better solution though would be to add the mitmproxy CA certificate
found in <code>~/.mitmproxy/mitmproxy-ca-cert.pem</code> to the system trusted
certificates. This will vary depending on your OS and distribution, but
in my case that would be done with:</p>
<pre><code class="hljs language-sh">sudo trust anchor ~/.mitmproxy/mitmproxy-ca-cert.pem
</code></pre>
<p>Then the <code>curl</code> command should work without <code>--insecure</code>!</p>
<h3 id="short-version" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html#short-version"><span>Short version</span></a></h3>
<p>Finally, if you don‚Äôt want to bother running <code>local/graftcp-local</code> and
<code>./graftcp</code> separately, you can instead use <code>local/mgraftcp</code>. If you
still use the SOCKS5 proxy on port 1080:</p>
<pre><code class="hljs language-sh"><span class="hljs-built_in">local</span>/mgraftcp curl https://www.codejam.info/
</code></pre>
<p>Or with a HTTP proxy on port 8080:</p>
<pre><code class="hljs language-sh"><span class="hljs-built_in">local</span>/mgraftcp --http_proxy localhost:8080 --select_proxy_mode only_http_proxy curl https://www.codejam.info/
</code></pre>
<p>This is useful if you only want to use graftcp for a single command, or
don‚Äôt mind configure the proxy settings every single time. Otherwise the
graftcp server method with <code>local/graftcp-local</code> works better as you
only have to configure your proxy once and any call to <code>./graftcp</code> will
use it!</p>
<h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="https://www.codejam.info/2022/04/graftcp-inspect-https-traffic-proxy.html#conclusion"><span>Conclusion</span></a></h2>
<p>graftcp is a really powerful tool that allows you to redirect HTTPS
traffic through a proxy of your choice, even in situations where this
wouldn‚Äôt be allowed or planned for.</p>
<p>Because I love inspecting programs‚Äô network traffic to know how they
work, and it‚Äôs not always easy to get access to their requests logs,
graftcp is now a go-to of mine for this kind of task, as it‚Äôs proven to
work flawlessly and very reliably, even with statically linked binaries
and programs that don‚Äôt link against libc like it‚Äôs the case with Go!</p>
<p>I hope you learnt something with this post, and I wish you a happy
network sniffing. ü§ò</p>
<section class="post-footer">
  <h3>Want to leave a comment?</h3>
  <p>
    Join the discussion on <a href="https://twitter.com/valeriangalliat/status/1520528360182620160">Twitter</a> or send me an <a href="mailto:val@codejam.info">email</a>! üíå<br>
    This post helped you? <a href="https://ko-fi.com/funkyval">Buy me a coffee</a>! üçª
  </p>
</section>
]]></content>
  </entry>
</feed>
